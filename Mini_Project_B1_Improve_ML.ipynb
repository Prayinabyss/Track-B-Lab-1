{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62gkk4_lKztu"
      },
      "source": [
        "# EEC 174AY 2023 Fall Mini Project B1: Improve your ML model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc654drGKztv"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NYkq2beKztw"
      },
      "source": [
        "This asignment follows Lab2 and uses the same dataset as Lab2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBtNuNPcKztx"
      },
      "source": [
        "### Reading Data into Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKZVXLZfKztx"
      },
      "outputs": [],
      "source": [
        "# make sure we can plot in future if we want\n",
        "%matplotlib notebook\n",
        "# make sure to ignore warnings\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "# Import statement for pandas\n",
        "import pandas as pd\n",
        "# This is just a small configuration change for purposes of the class\n",
        "pd.options.display.max_rows = 10\n",
        "\n",
        "# Get our train X and y datasets for the problem\n",
        "train_x = pd.read_csv('ece174_pva_train_x.csv')\n",
        "train_y = pd.read_csv('ece174_pva_train_y.csv')\n",
        "\n",
        "# Get our validation X and y datasets for the problem.\n",
        "test_x = pd.read_csv('ece174_pva_validation_x.csv')\n",
        "test_y = pd.read_csv('ece174_pva_validation_y.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRttEP9VKzt0",
        "outputId": "e05f6f7b-5145-4aee-a987-5bc1ac281680"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breath_id</th>\n",
              "      <th>i_time</th>\n",
              "      <th>tve</th>\n",
              "      <th>max_flow</th>\n",
              "      <th>min_flow</th>\n",
              "      <th>max_pressure</th>\n",
              "      <th>peep</th>\n",
              "      <th>ip_auc</th>\n",
              "      <th>ep_auc</th>\n",
              "      <th>patient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "      <td>545.032222</td>\n",
              "      <td>51.06</td>\n",
              "      <td>-41.03</td>\n",
              "      <td>17.37</td>\n",
              "      <td>7.600</td>\n",
              "      <td>11.122367</td>\n",
              "      <td>16.057733</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.80</td>\n",
              "      <td>531.880278</td>\n",
              "      <td>53.13</td>\n",
              "      <td>-39.97</td>\n",
              "      <td>17.13</td>\n",
              "      <td>7.508</td>\n",
              "      <td>11.077750</td>\n",
              "      <td>17.310533</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.86</td>\n",
              "      <td>523.876667</td>\n",
              "      <td>52.86</td>\n",
              "      <td>-38.24</td>\n",
              "      <td>17.11</td>\n",
              "      <td>7.658</td>\n",
              "      <td>12.066000</td>\n",
              "      <td>16.697800</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.80</td>\n",
              "      <td>507.636111</td>\n",
              "      <td>51.04</td>\n",
              "      <td>-39.37</td>\n",
              "      <td>17.14</td>\n",
              "      <td>7.572</td>\n",
              "      <td>11.097800</td>\n",
              "      <td>15.774250</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.80</td>\n",
              "      <td>518.618889</td>\n",
              "      <td>47.88</td>\n",
              "      <td>-38.51</td>\n",
              "      <td>16.92</td>\n",
              "      <td>7.598</td>\n",
              "      <td>11.065400</td>\n",
              "      <td>18.483333</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5970</th>\n",
              "      <td>296</td>\n",
              "      <td>0.90</td>\n",
              "      <td>355.365278</td>\n",
              "      <td>42.26</td>\n",
              "      <td>-51.51</td>\n",
              "      <td>23.53</td>\n",
              "      <td>13.194</td>\n",
              "      <td>19.216400</td>\n",
              "      <td>21.816367</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5971</th>\n",
              "      <td>297</td>\n",
              "      <td>0.90</td>\n",
              "      <td>316.806944</td>\n",
              "      <td>42.10</td>\n",
              "      <td>-55.17</td>\n",
              "      <td>24.61</td>\n",
              "      <td>12.896</td>\n",
              "      <td>19.800467</td>\n",
              "      <td>21.739700</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5972</th>\n",
              "      <td>298</td>\n",
              "      <td>0.92</td>\n",
              "      <td>395.971111</td>\n",
              "      <td>42.95</td>\n",
              "      <td>-22.47</td>\n",
              "      <td>21.35</td>\n",
              "      <td>13.090</td>\n",
              "      <td>16.997767</td>\n",
              "      <td>21.457600</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5973</th>\n",
              "      <td>299</td>\n",
              "      <td>0.90</td>\n",
              "      <td>373.426389</td>\n",
              "      <td>40.34</td>\n",
              "      <td>-36.81</td>\n",
              "      <td>21.69</td>\n",
              "      <td>13.334</td>\n",
              "      <td>17.944000</td>\n",
              "      <td>21.798167</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5974</th>\n",
              "      <td>300</td>\n",
              "      <td>0.90</td>\n",
              "      <td>364.684444</td>\n",
              "      <td>42.29</td>\n",
              "      <td>-45.94</td>\n",
              "      <td>22.69</td>\n",
              "      <td>13.002</td>\n",
              "      <td>18.679800</td>\n",
              "      <td>21.801950</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5975 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      breath_id  i_time         tve  max_flow  min_flow  max_pressure    peep  \\\n",
              "0             1    0.80  545.032222     51.06    -41.03         17.37   7.600   \n",
              "1             2    0.80  531.880278     53.13    -39.97         17.13   7.508   \n",
              "2             3    0.86  523.876667     52.86    -38.24         17.11   7.658   \n",
              "3             4    0.80  507.636111     51.04    -39.37         17.14   7.572   \n",
              "4             5    0.80  518.618889     47.88    -38.51         16.92   7.598   \n",
              "...         ...     ...         ...       ...       ...           ...     ...   \n",
              "5970        296    0.90  355.365278     42.26    -51.51         23.53  13.194   \n",
              "5971        297    0.90  316.806944     42.10    -55.17         24.61  12.896   \n",
              "5972        298    0.92  395.971111     42.95    -22.47         21.35  13.090   \n",
              "5973        299    0.90  373.426389     40.34    -36.81         21.69  13.334   \n",
              "5974        300    0.90  364.684444     42.29    -45.94         22.69  13.002   \n",
              "\n",
              "         ip_auc     ep_auc  patient  \n",
              "0     11.122367  16.057733       66  \n",
              "1     11.077750  17.310533       66  \n",
              "2     12.066000  16.697800       66  \n",
              "3     11.097800  15.774250       66  \n",
              "4     11.065400  18.483333       66  \n",
              "...         ...        ...      ...  \n",
              "5970  19.216400  21.816367      662  \n",
              "5971  19.800467  21.739700      662  \n",
              "5972  16.997767  21.457600      662  \n",
              "5973  17.944000  21.798167      662  \n",
              "5974  18.679800  21.801950      662  \n",
              "\n",
              "[5975 rows x 10 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# output some rows of the dataset just to get a better feel for the information\n",
        "train_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mznyk0N3Kzt4"
      },
      "source": [
        "Here we have 18 columns. I'm going to give a detailed breakdown here. Feel free to come back to it as necessary.\n",
        "\n",
        "Features:\n",
        " * *breath_id* - matches with a specific breath identifier from the raw data file.\n",
        " * *patient* - the patient the data came from\n",
        " * *min_flow* - The minimum flow observation on the breath\n",
        " * *max_flow* - The maximum flow observation on the breath\n",
        " * *tvi* - The inhaled volume of air for each breath\n",
        " * *tve* - The exhaled volume of air for each breath\n",
        " * *tve_tvi_ratio* - The ratio of `tve / tvi`\n",
        " * *i_time* - The amount of time patient was breathing in for each breath\n",
        " * *e_time* - The amount of time patient was breathing out for each breath\n",
        " * *ie_ratio* - The ratio of `i_time / e_time`\n",
        " * *rr* - The respiratory rate in number of breaths per minute. Measured by `60 / (i_time + e_time)`\n",
        " * *min_pressure* - the minimum pressure observation on the breath\n",
        " * *max_pressure* - the maximum pressure observation on the breath\n",
        " * *peep* - the baseline pressure setting on the ventilator\n",
        " * *pip* - the maximum pressure setting of inspiration. Slight difference compared to max_pressure\n",
        " * *maw* - the mean pressure for the entire breath\n",
        " * *ip_auc* - the area under the curve of the inspiratory pressure\n",
        " * *ep_auc* - the area under the curve of the expiratory pressure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOjD7m2NKzt5"
      },
      "source": [
        "## Featurization\n",
        "\n",
        "Featurization is the process where you extract information from raw data. This information can then be fed into a machine learning algorithm to perform the task you want. In the current case we will need to extract additional information from the ventilator data in order to create a valid machine learning classifier.\n",
        "\n",
        "### Processing the Data\n",
        "The first step we need to do is to be able to read the raw data files and put them into memory. We have taken this problem away from you for the purposes of this homework and have given you the code so that you can do this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVmOloDxKzt5"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "def process_ventilator_data(filename):\n",
        "    descriptor = open(filename)\n",
        "    reader = csv.reader(descriptor)\n",
        "    breath_id = 1\n",
        "\n",
        "    all_breath_data = []\n",
        "    current_flow_data = []\n",
        "    current_pressure_data = []\n",
        "\n",
        "    for row in reader:\n",
        "        if (row[0].strip() == 'BS' or row[0].strip() == 'BE') and current_flow_data != []:\n",
        "            all_breath_data.append({'breath_id': breath_id, 'flow': current_flow_data, 'pressure': current_pressure_data})\n",
        "            breath_id += 1\n",
        "            current_flow_data = []\n",
        "            current_pressure_data = []\n",
        "        else:\n",
        "            try:\n",
        "                current_flow_data.append(round(float(row[0]), 2))\n",
        "                current_pressure_data.append(round(float(row[1]), 2))\n",
        "            except (IndexError, ValueError):\n",
        "                continue\n",
        "    return all_breath_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRcI4TUWKzt8"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import os\n",
        "\n",
        "# import for Simpson's method. This will be helpful for calculating TVi\n",
        "from scipy.integrate import simps\n",
        "from statistics import mean\n",
        "\n",
        "\n",
        "def extract_features_for_file(filename, existing_features):\n",
        "    \"\"\"\n",
        "    Extract features for every single breath in file. To make matters a bit easier, we use\n",
        "    existing features that we've already extracted from the file to help speed the process.\n",
        "    \"\"\"\n",
        "    patient = filename.split('/')[-2]\n",
        "    all_breath_data = process_ventilator_data(filename)\n",
        "    all_features = []\n",
        "\n",
        "    for breath_data in all_breath_data:\n",
        "        breath_id = breath_data['breath_id']\n",
        "        existing_breath_features = existing_features[existing_features.breath_id == breath_id].iloc[0]\n",
        "\n",
        "        flow = breath_data['flow']\n",
        "        pressure = breath_data['pressure']\n",
        "\n",
        "        # inspiratory time (the amount of time a patient is inhaling for)\n",
        "        i_time = existing_breath_features.i_time\n",
        "        # exhaled tidal volume\n",
        "        tve = existing_breath_features.tve\n",
        "        # maximum flow for breath\n",
        "        max_flow = existing_breath_features.max_flow\n",
        "        # minimum flow for the breath\n",
        "        min_flow = existing_breath_features.min_flow\n",
        "        # maximum pressure for the breath\n",
        "        max_pressure = existing_breath_features.max_pressure\n",
        "        # The minimum pressure setting on the ventilator\n",
        "        peep = existing_breath_features.peep\n",
        "        # The area under the curve of the inspiratory pressure curve\n",
        "        ip_auc = existing_breath_features.ip_auc\n",
        "        # The area under the curve of the expiratory pressure curve\n",
        "        ep_auc = existing_breath_features.ep_auc\n",
        "\n",
        "        # This is the array index where the inhalation ends. We divide by 0.02 because\n",
        "        # thats how frequently the ventilator samples data, every 0.02 seconds.\n",
        "        x0_index = int(i_time / 0.02)\n",
        "\n",
        "        # Part of your assignment is to extract the following features for all breaths:\n",
        "        #\n",
        "        # Expiratory Time. The amount of time a patient is exhaling\n",
        "        e_time = len(flow) * .02 - i_time\n",
        "        #\n",
        "        # I:E ratio. The ratio of inspiratory to expiratory time. Measured by i_time/e_time\n",
        "        i_e_ratio = i_time / e_time\n",
        "        #\n",
        "        # Respiratory rate. The number of breaths a patient is breathing. This is measured by\n",
        "        # 60 / (total breath time in seconds)\n",
        "        rr = 60 / (i_time + e_time)\n",
        "        rr = 60 / (len(flow) * .02)\n",
        "        #\n",
        "        # Tidal volume inhaled. The amount of air volume inhaled in the breath.\n",
        "        # Hint: use the simps function.\n",
        "        # This will output volume in L/min, convert to ml/sec (* 1000 / 60)\n",
        "        tvi = simps(flow[:x0_index], dx=0.02) * 1000 / 60\n",
        "        #\n",
        "        # Tidal volume ratio. Measured by tve/tvi\n",
        "        tve_tvi_ratio = tve / tvi\n",
        "        #\n",
        "        # Minimum pressure of the breath\n",
        "        min_pressure = min(pressure)\n",
        "        #\n",
        "        # PIP - peak inspiratory pressure. The peak pressure during inhalation\n",
        "        pip = max(pressure[:x0_index])\n",
        "        #\n",
        "        # MAW - mean airway pressure for inhalation.\n",
        "        maw = mean(pressure[:x0_index])\n",
        "\n",
        "        all_features.append([\n",
        "            breath_id, i_time, e_time, i_e_ratio, rr, tvi, tve, tve_tvi_ratio,\n",
        "            max_flow, min_flow, max_pressure, min_pressure, pip, maw,\n",
        "            peep, ip_auc, ep_auc, int(patient)\n",
        "        ])\n",
        "    columns = [\n",
        "        'breath_id', 'i_time', 'e_time', 'i_e_ratio', 'rr', 'tvi', 'tve',\n",
        "        'tve_tvi_ratio', 'max_flow', 'min_flow', 'max_pressure',\n",
        "        'min_pressure', 'pip', 'maw', 'peep', 'ip_auc', 'ep_auc', 'patient'\n",
        "    ]\n",
        "    return all_features, columns\n",
        "\n",
        "\n",
        "def remake_dataset(dataset):\n",
        "    data_files = glob(os.path.join('data', '*/*.csv'))\n",
        "\n",
        "    patient_to_file_map = {}\n",
        "    for filename in data_files:\n",
        "        patient = filename.split('/')[-2]  # patient is embedded in this part of filename\n",
        "        patient_to_file_map[patient] = filename\n",
        "\n",
        "    data = []\n",
        "    # iterate over all the unique patients in the train set\n",
        "    for patient in dataset.patient.unique():\n",
        "        existing_features = dataset[dataset.patient == patient]\n",
        "        filename = patient_to_file_map[str(patient)]\n",
        "        breath_data, columns = extract_features_for_file(filename, existing_features)\n",
        "        # add breath rows\n",
        "        data.extend(breath_data)\n",
        "    # create new data frame with the new added information\n",
        "    return pd.DataFrame(data, columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIFPJtktKzt-"
      },
      "outputs": [],
      "source": [
        "# remake train set\n",
        "train_x = remake_dataset(train_x)\n",
        "# remake validation set.\n",
        "test_x = remake_dataset(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xnjp0FmuKzuA",
        "outputId": "44336221-6fe4-42bf-a7be-4b7155991b50"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breath_id</th>\n",
              "      <th>i_time</th>\n",
              "      <th>e_time</th>\n",
              "      <th>i_e_ratio</th>\n",
              "      <th>rr</th>\n",
              "      <th>tvi</th>\n",
              "      <th>tve</th>\n",
              "      <th>tve_tvi_ratio</th>\n",
              "      <th>max_flow</th>\n",
              "      <th>min_flow</th>\n",
              "      <th>max_pressure</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>pip</th>\n",
              "      <th>maw</th>\n",
              "      <th>peep</th>\n",
              "      <th>ip_auc</th>\n",
              "      <th>ep_auc</th>\n",
              "      <th>patient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.66</td>\n",
              "      <td>0.481928</td>\n",
              "      <td>24.390244</td>\n",
              "      <td>481.923056</td>\n",
              "      <td>545.032222</td>\n",
              "      <td>1.130953</td>\n",
              "      <td>51.06</td>\n",
              "      <td>-41.03</td>\n",
              "      <td>17.37</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.37</td>\n",
              "      <td>14.208500</td>\n",
              "      <td>7.600</td>\n",
              "      <td>11.122367</td>\n",
              "      <td>16.057733</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>484.712500</td>\n",
              "      <td>531.880278</td>\n",
              "      <td>1.097311</td>\n",
              "      <td>53.13</td>\n",
              "      <td>-39.97</td>\n",
              "      <td>17.13</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.13</td>\n",
              "      <td>14.149500</td>\n",
              "      <td>7.508</td>\n",
              "      <td>11.077750</td>\n",
              "      <td>17.310533</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.74</td>\n",
              "      <td>0.494253</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>521.370000</td>\n",
              "      <td>523.876667</td>\n",
              "      <td>1.004808</td>\n",
              "      <td>52.86</td>\n",
              "      <td>-38.24</td>\n",
              "      <td>17.11</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.11</td>\n",
              "      <td>14.311860</td>\n",
              "      <td>7.658</td>\n",
              "      <td>12.066000</td>\n",
              "      <td>16.697800</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.64</td>\n",
              "      <td>0.487805</td>\n",
              "      <td>24.590164</td>\n",
              "      <td>483.921389</td>\n",
              "      <td>507.636111</td>\n",
              "      <td>1.049005</td>\n",
              "      <td>51.04</td>\n",
              "      <td>-39.37</td>\n",
              "      <td>17.14</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.14</td>\n",
              "      <td>14.174500</td>\n",
              "      <td>7.572</td>\n",
              "      <td>11.097800</td>\n",
              "      <td>15.774250</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.94</td>\n",
              "      <td>0.412371</td>\n",
              "      <td>21.897810</td>\n",
              "      <td>466.293611</td>\n",
              "      <td>518.618889</td>\n",
              "      <td>1.112215</td>\n",
              "      <td>47.88</td>\n",
              "      <td>-38.51</td>\n",
              "      <td>16.92</td>\n",
              "      <td>7.04</td>\n",
              "      <td>16.92</td>\n",
              "      <td>14.131250</td>\n",
              "      <td>7.598</td>\n",
              "      <td>11.065400</td>\n",
              "      <td>18.483333</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5970</th>\n",
              "      <td>296</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>349.682222</td>\n",
              "      <td>355.365278</td>\n",
              "      <td>1.016252</td>\n",
              "      <td>42.26</td>\n",
              "      <td>-51.51</td>\n",
              "      <td>23.53</td>\n",
              "      <td>13.00</td>\n",
              "      <td>23.53</td>\n",
              "      <td>21.750667</td>\n",
              "      <td>13.194</td>\n",
              "      <td>19.216400</td>\n",
              "      <td>21.816367</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5971</th>\n",
              "      <td>297</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>350.130000</td>\n",
              "      <td>316.806944</td>\n",
              "      <td>0.904827</td>\n",
              "      <td>42.10</td>\n",
              "      <td>-55.17</td>\n",
              "      <td>24.61</td>\n",
              "      <td>12.80</td>\n",
              "      <td>24.61</td>\n",
              "      <td>22.414667</td>\n",
              "      <td>12.896</td>\n",
              "      <td>19.800467</td>\n",
              "      <td>21.739700</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5972</th>\n",
              "      <td>298</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1.58</td>\n",
              "      <td>0.582278</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>354.443333</td>\n",
              "      <td>395.971111</td>\n",
              "      <td>1.117163</td>\n",
              "      <td>42.95</td>\n",
              "      <td>-22.47</td>\n",
              "      <td>21.35</td>\n",
              "      <td>12.90</td>\n",
              "      <td>21.35</td>\n",
              "      <td>18.785435</td>\n",
              "      <td>13.090</td>\n",
              "      <td>16.997767</td>\n",
              "      <td>21.457600</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5973</th>\n",
              "      <td>299</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>337.941111</td>\n",
              "      <td>373.426389</td>\n",
              "      <td>1.105004</td>\n",
              "      <td>40.34</td>\n",
              "      <td>-36.81</td>\n",
              "      <td>21.69</td>\n",
              "      <td>13.02</td>\n",
              "      <td>21.69</td>\n",
              "      <td>20.308444</td>\n",
              "      <td>13.334</td>\n",
              "      <td>17.944000</td>\n",
              "      <td>21.798167</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5974</th>\n",
              "      <td>300</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>342.556667</td>\n",
              "      <td>364.684444</td>\n",
              "      <td>1.064596</td>\n",
              "      <td>42.29</td>\n",
              "      <td>-45.94</td>\n",
              "      <td>22.69</td>\n",
              "      <td>12.90</td>\n",
              "      <td>22.69</td>\n",
              "      <td>21.145778</td>\n",
              "      <td>13.002</td>\n",
              "      <td>18.679800</td>\n",
              "      <td>21.801950</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5975 rows Ã— 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      breath_id  i_time  e_time  i_e_ratio         rr         tvi         tve  \\\n",
              "0             1    0.80    1.66   0.481928  24.390244  481.923056  545.032222   \n",
              "1             2    0.80    1.80   0.444444  23.076923  484.712500  531.880278   \n",
              "2             3    0.86    1.74   0.494253  23.076923  521.370000  523.876667   \n",
              "3             4    0.80    1.64   0.487805  24.590164  483.921389  507.636111   \n",
              "4             5    0.80    1.94   0.412371  21.897810  466.293611  518.618889   \n",
              "...         ...     ...     ...        ...        ...         ...         ...   \n",
              "5970        296    0.90    1.60   0.562500  24.000000  349.682222  355.365278   \n",
              "5971        297    0.90    1.60   0.562500  24.000000  350.130000  316.806944   \n",
              "5972        298    0.92    1.58   0.582278  24.000000  354.443333  395.971111   \n",
              "5973        299    0.90    1.60   0.562500  24.000000  337.941111  373.426389   \n",
              "5974        300    0.90    1.60   0.562500  24.000000  342.556667  364.684444   \n",
              "\n",
              "      tve_tvi_ratio  max_flow  min_flow  max_pressure  min_pressure    pip  \\\n",
              "0          1.130953     51.06    -41.03         17.37          7.04  17.37   \n",
              "1          1.097311     53.13    -39.97         17.13          7.04  17.13   \n",
              "2          1.004808     52.86    -38.24         17.11          7.04  17.11   \n",
              "3          1.049005     51.04    -39.37         17.14          7.04  17.14   \n",
              "4          1.112215     47.88    -38.51         16.92          7.04  16.92   \n",
              "...             ...       ...       ...           ...           ...    ...   \n",
              "5970       1.016252     42.26    -51.51         23.53         13.00  23.53   \n",
              "5971       0.904827     42.10    -55.17         24.61         12.80  24.61   \n",
              "5972       1.117163     42.95    -22.47         21.35         12.90  21.35   \n",
              "5973       1.105004     40.34    -36.81         21.69         13.02  21.69   \n",
              "5974       1.064596     42.29    -45.94         22.69         12.90  22.69   \n",
              "\n",
              "            maw    peep     ip_auc     ep_auc  patient  \n",
              "0     14.208500   7.600  11.122367  16.057733       66  \n",
              "1     14.149500   7.508  11.077750  17.310533       66  \n",
              "2     14.311860   7.658  12.066000  16.697800       66  \n",
              "3     14.174500   7.572  11.097800  15.774250       66  \n",
              "4     14.131250   7.598  11.065400  18.483333       66  \n",
              "...         ...     ...        ...        ...      ...  \n",
              "5970  21.750667  13.194  19.216400  21.816367      662  \n",
              "5971  22.414667  12.896  19.800467  21.739700      662  \n",
              "5972  18.785435  13.090  16.997767  21.457600      662  \n",
              "5973  20.308444  13.334  17.944000  21.798167      662  \n",
              "5974  21.145778  13.002  18.679800  21.801950      662  \n",
              "\n",
              "[5975 rows x 18 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilPoq-riKzuD"
      },
      "source": [
        "### Create Ground Truth (that the machine understands)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZyvPnXVKzuE",
        "outputId": "cb746889-51e6-46f0-f1e4-3231901b4ad4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breath_id</th>\n",
              "      <th>patient</th>\n",
              "      <th>bsa</th>\n",
              "      <th>dta</th>\n",
              "      <th>cough</th>\n",
              "      <th>suction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>292</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1242</th>\n",
              "      <td>295</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1243</th>\n",
              "      <td>296</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1244</th>\n",
              "      <td>297</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1245</th>\n",
              "      <td>298</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1246</th>\n",
              "      <td>299</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1247 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      breath_id  patient  bsa  dta  cough  suction\n",
              "0            20      292    1    0      0        0\n",
              "1            21      292    1    0      0        0\n",
              "2            22      292    0    0      0        0\n",
              "3            23      292    1    0      0        0\n",
              "4            24      292    1    0      0        0\n",
              "...         ...      ...  ...  ...    ...      ...\n",
              "1242        295      114    0    0      0        0\n",
              "1243        296      114    0    0      0        0\n",
              "1244        297      114    0    0      0        0\n",
              "1245        298      114    0    0      0        0\n",
              "1246        299      114    0    0      0        0\n",
              "\n",
              "[1247 rows x 6 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read the test dataset and set it up. Technically we're using the validation set.\n",
        "test_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtS2Cl7NKzuG"
      },
      "source": [
        "What does this mean?\n",
        "\n",
        "We have 6 columns here\n",
        " * *breath_id* - matches with a specific breath identifier from the raw data file.\n",
        " * *patient* - the patient the data came from\n",
        " * *bsa* - Breath Stacking Asynchrony. A single breath where the patient is trapping air in their chest\n",
        " * *dta* - Double Trigger Asynchrony. Two breaths in a row where the patient is trapping air\n",
        " * *cough* - What it sounds like, when a patient coughs\n",
        " * *suction* -  Nurses perform suction procedures to remove excess fluid from an endotracheal tube. This waveform is indicative of that.\n",
        "\n",
        "Now that we understand what our columns are, we need to put it into a format where the machine can understand it and create a learning model. Because this is a multiclass model, let's just have non-PVA breaths be class 0, breath stacking can be class 1, double trigger can be class 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE44UfwtKzuG",
        "outputId": "68fede4c-4368-452f-f70c-2b61548af3a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       0\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "1242    0\n",
              "1243    0\n",
              "1244    0\n",
              "1245    0\n",
              "1246    0\n",
              "Length: 1247, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a multi-class y vector that we can use for training purposes.\n",
        "train_y_vector = train_y.bsa * 1 + train_y.dta * 2\n",
        "test_y_vector = test_y.bsa * 1 + test_y.dta * 2\n",
        "test_y_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzrRJ5-SKzuJ",
        "outputId": "ef2dea76-f6c2-448d-81e5-46c47a172adf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5438    3\n",
              "5440    3\n",
              "5521    3\n",
              "dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# See if there places where the data was mis-annotated, where both double trigger and breath stack was annotated.\n",
        "# It's just good to know if this is happening or not so that we can either drop the data, or change it later on.\n",
        "train_y_vector[train_y_vector > 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8FoDLUZKzuM"
      },
      "source": [
        "### Creating a Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Th1VdBy0KzuM"
      },
      "outputs": [],
      "source": [
        "# Need to finalize dataset and remove misannotated examples first.\n",
        "\n",
        "# just drop places where data is double annotated.\n",
        "misannotated_train = train_y_vector > 2\n",
        "misannotated_test = test_y_vector > 2\n",
        "\n",
        "# ~ is the NOT operator\n",
        "train_x = train_x.loc[~misannotated_train]\n",
        "train_y_vector = train_y_vector.loc[~misannotated_train]\n",
        "\n",
        "# do same thing for test\n",
        "test_x = test_x.loc[~misannotated_test]\n",
        "test_y_vector = test_y_vector.loc[~misannotated_test]\n",
        "\n",
        "\n",
        "\n",
        "# Also make sure to drop data that is NaN. This is very important because otherwise your model won't train.\n",
        "# The .any(axis=1) function basically says, if there are any nans in this *ROW* then mark the row as true.\n",
        "# The .any(axis=0) would mark columns as True/False, but this isn't helpful now.\n",
        "nans_train = train_x.isna().any(axis=1)\n",
        "nans_test = test_x.isna().any(axis=1)\n",
        "\n",
        "# now filter them out of the dataset in the same way\n",
        "train_x = train_x.loc[~nans_train]\n",
        "train_y_vector = train_y_vector.loc[~nans_train]\n",
        "\n",
        "test_x = test_x.loc[~nans_test]\n",
        "test_y_vector = test_y_vector.loc[~nans_test]\n",
        "\n",
        "\n",
        "# any time we drop things from a data frame or series in pandas it is often helpful to re-index the object.\n",
        "# the index is usually a sequential ordering of the rows like 1, 2, ... n. Sometimes it can be different\n",
        "# but for now we'll just use sequential ordering\n",
        "train_x.index = range(len(train_x))\n",
        "train_y_vector.index = range(len(train_y_vector))\n",
        "\n",
        "test_x.index = range(len(test_x))\n",
        "test_y_vector.index = range(len(test_y_vector))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCCAgbrGKzuP",
        "outputId": "e5a501b8-42b8-4686-93cb-eb528aebf654"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breath_id</th>\n",
              "      <th>i_time</th>\n",
              "      <th>e_time</th>\n",
              "      <th>i_e_ratio</th>\n",
              "      <th>rr</th>\n",
              "      <th>tvi</th>\n",
              "      <th>tve</th>\n",
              "      <th>tve_tvi_ratio</th>\n",
              "      <th>max_flow</th>\n",
              "      <th>min_flow</th>\n",
              "      <th>max_pressure</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>pip</th>\n",
              "      <th>maw</th>\n",
              "      <th>peep</th>\n",
              "      <th>ip_auc</th>\n",
              "      <th>ep_auc</th>\n",
              "      <th>patient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.66</td>\n",
              "      <td>0.481928</td>\n",
              "      <td>24.390244</td>\n",
              "      <td>481.923056</td>\n",
              "      <td>545.032222</td>\n",
              "      <td>1.130953</td>\n",
              "      <td>51.06</td>\n",
              "      <td>-41.03</td>\n",
              "      <td>17.37</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.37</td>\n",
              "      <td>14.208500</td>\n",
              "      <td>7.600</td>\n",
              "      <td>11.122367</td>\n",
              "      <td>16.057733</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>484.712500</td>\n",
              "      <td>531.880278</td>\n",
              "      <td>1.097311</td>\n",
              "      <td>53.13</td>\n",
              "      <td>-39.97</td>\n",
              "      <td>17.13</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.13</td>\n",
              "      <td>14.149500</td>\n",
              "      <td>7.508</td>\n",
              "      <td>11.077750</td>\n",
              "      <td>17.310533</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.74</td>\n",
              "      <td>0.494253</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>521.370000</td>\n",
              "      <td>523.876667</td>\n",
              "      <td>1.004808</td>\n",
              "      <td>52.86</td>\n",
              "      <td>-38.24</td>\n",
              "      <td>17.11</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.11</td>\n",
              "      <td>14.311860</td>\n",
              "      <td>7.658</td>\n",
              "      <td>12.066000</td>\n",
              "      <td>16.697800</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.64</td>\n",
              "      <td>0.487805</td>\n",
              "      <td>24.590164</td>\n",
              "      <td>483.921389</td>\n",
              "      <td>507.636111</td>\n",
              "      <td>1.049005</td>\n",
              "      <td>51.04</td>\n",
              "      <td>-39.37</td>\n",
              "      <td>17.14</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.14</td>\n",
              "      <td>14.174500</td>\n",
              "      <td>7.572</td>\n",
              "      <td>11.097800</td>\n",
              "      <td>15.774250</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.94</td>\n",
              "      <td>0.412371</td>\n",
              "      <td>21.897810</td>\n",
              "      <td>466.293611</td>\n",
              "      <td>518.618889</td>\n",
              "      <td>1.112215</td>\n",
              "      <td>47.88</td>\n",
              "      <td>-38.51</td>\n",
              "      <td>16.92</td>\n",
              "      <td>7.04</td>\n",
              "      <td>16.92</td>\n",
              "      <td>14.131250</td>\n",
              "      <td>7.598</td>\n",
              "      <td>11.065400</td>\n",
              "      <td>18.483333</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5967</th>\n",
              "      <td>296</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>349.682222</td>\n",
              "      <td>355.365278</td>\n",
              "      <td>1.016252</td>\n",
              "      <td>42.26</td>\n",
              "      <td>-51.51</td>\n",
              "      <td>23.53</td>\n",
              "      <td>13.00</td>\n",
              "      <td>23.53</td>\n",
              "      <td>21.750667</td>\n",
              "      <td>13.194</td>\n",
              "      <td>19.216400</td>\n",
              "      <td>21.816367</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5968</th>\n",
              "      <td>297</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>350.130000</td>\n",
              "      <td>316.806944</td>\n",
              "      <td>0.904827</td>\n",
              "      <td>42.10</td>\n",
              "      <td>-55.17</td>\n",
              "      <td>24.61</td>\n",
              "      <td>12.80</td>\n",
              "      <td>24.61</td>\n",
              "      <td>22.414667</td>\n",
              "      <td>12.896</td>\n",
              "      <td>19.800467</td>\n",
              "      <td>21.739700</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5969</th>\n",
              "      <td>298</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1.58</td>\n",
              "      <td>0.582278</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>354.443333</td>\n",
              "      <td>395.971111</td>\n",
              "      <td>1.117163</td>\n",
              "      <td>42.95</td>\n",
              "      <td>-22.47</td>\n",
              "      <td>21.35</td>\n",
              "      <td>12.90</td>\n",
              "      <td>21.35</td>\n",
              "      <td>18.785435</td>\n",
              "      <td>13.090</td>\n",
              "      <td>16.997767</td>\n",
              "      <td>21.457600</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5970</th>\n",
              "      <td>299</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>337.941111</td>\n",
              "      <td>373.426389</td>\n",
              "      <td>1.105004</td>\n",
              "      <td>40.34</td>\n",
              "      <td>-36.81</td>\n",
              "      <td>21.69</td>\n",
              "      <td>13.02</td>\n",
              "      <td>21.69</td>\n",
              "      <td>20.308444</td>\n",
              "      <td>13.334</td>\n",
              "      <td>17.944000</td>\n",
              "      <td>21.798167</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5971</th>\n",
              "      <td>300</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>342.556667</td>\n",
              "      <td>364.684444</td>\n",
              "      <td>1.064596</td>\n",
              "      <td>42.29</td>\n",
              "      <td>-45.94</td>\n",
              "      <td>22.69</td>\n",
              "      <td>12.90</td>\n",
              "      <td>22.69</td>\n",
              "      <td>21.145778</td>\n",
              "      <td>13.002</td>\n",
              "      <td>18.679800</td>\n",
              "      <td>21.801950</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5972 rows Ã— 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      breath_id  i_time  e_time  i_e_ratio         rr         tvi         tve  \\\n",
              "0             1    0.80    1.66   0.481928  24.390244  481.923056  545.032222   \n",
              "1             2    0.80    1.80   0.444444  23.076923  484.712500  531.880278   \n",
              "2             3    0.86    1.74   0.494253  23.076923  521.370000  523.876667   \n",
              "3             4    0.80    1.64   0.487805  24.590164  483.921389  507.636111   \n",
              "4             5    0.80    1.94   0.412371  21.897810  466.293611  518.618889   \n",
              "...         ...     ...     ...        ...        ...         ...         ...   \n",
              "5967        296    0.90    1.60   0.562500  24.000000  349.682222  355.365278   \n",
              "5968        297    0.90    1.60   0.562500  24.000000  350.130000  316.806944   \n",
              "5969        298    0.92    1.58   0.582278  24.000000  354.443333  395.971111   \n",
              "5970        299    0.90    1.60   0.562500  24.000000  337.941111  373.426389   \n",
              "5971        300    0.90    1.60   0.562500  24.000000  342.556667  364.684444   \n",
              "\n",
              "      tve_tvi_ratio  max_flow  min_flow  max_pressure  min_pressure    pip  \\\n",
              "0          1.130953     51.06    -41.03         17.37          7.04  17.37   \n",
              "1          1.097311     53.13    -39.97         17.13          7.04  17.13   \n",
              "2          1.004808     52.86    -38.24         17.11          7.04  17.11   \n",
              "3          1.049005     51.04    -39.37         17.14          7.04  17.14   \n",
              "4          1.112215     47.88    -38.51         16.92          7.04  16.92   \n",
              "...             ...       ...       ...           ...           ...    ...   \n",
              "5967       1.016252     42.26    -51.51         23.53         13.00  23.53   \n",
              "5968       0.904827     42.10    -55.17         24.61         12.80  24.61   \n",
              "5969       1.117163     42.95    -22.47         21.35         12.90  21.35   \n",
              "5970       1.105004     40.34    -36.81         21.69         13.02  21.69   \n",
              "5971       1.064596     42.29    -45.94         22.69         12.90  22.69   \n",
              "\n",
              "            maw    peep     ip_auc     ep_auc  patient  \n",
              "0     14.208500   7.600  11.122367  16.057733       66  \n",
              "1     14.149500   7.508  11.077750  17.310533       66  \n",
              "2     14.311860   7.658  12.066000  16.697800       66  \n",
              "3     14.174500   7.572  11.097800  15.774250       66  \n",
              "4     14.131250   7.598  11.065400  18.483333       66  \n",
              "...         ...     ...        ...        ...      ...  \n",
              "5967  21.750667  13.194  19.216400  21.816367      662  \n",
              "5968  22.414667  12.896  19.800467  21.739700      662  \n",
              "5969  18.785435  13.090  16.997767  21.457600      662  \n",
              "5970  20.308444  13.334  17.944000  21.798167      662  \n",
              "5971  21.145778  13.002  18.679800  21.801950      662  \n",
              "\n",
              "[5972 rows x 18 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV5sP7CLKzun"
      },
      "source": [
        "__From Lab2, we know there are only 3 classes in our labels as shown below.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVdi-lDPKzun",
        "outputId": "a92ad0ff-deb2-47a6-fb7b-5e176bdc7e3d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breath_id</th>\n",
              "      <th>patient</th>\n",
              "      <th>bsa</th>\n",
              "      <th>dta</th>\n",
              "      <th>cough</th>\n",
              "      <th>suction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>292</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1242</th>\n",
              "      <td>295</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1243</th>\n",
              "      <td>296</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1244</th>\n",
              "      <td>297</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1245</th>\n",
              "      <td>298</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1246</th>\n",
              "      <td>299</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1247 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      breath_id  patient  bsa  dta  cough  suction\n",
              "0            20      292    1    0      0        0\n",
              "1            21      292    1    0      0        0\n",
              "2            22      292    0    0      0        0\n",
              "3            23      292    1    0      0        0\n",
              "4            24      292    1    0      0        0\n",
              "...         ...      ...  ...  ...    ...      ...\n",
              "1242        295      114    0    0      0        0\n",
              "1243        296      114    0    0      0        0\n",
              "1244        297      114    0    0      0        0\n",
              "1245        298      114    0    0      0        0\n",
              "1246        299      114    0    0      0        0\n",
              "\n",
              "[1247 rows x 6 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNrSsxopKzuu"
      },
      "source": [
        "__What does this mean?__\n",
        "\n",
        "We have 6 columns here\n",
        " * *breath_id* - matches with a specific breath identifier from the raw data file.\n",
        " * *patient* - the patient the data came from\n",
        " * *bsa* - Breath Stacking Asynchrony. A single breath where the patient is trapping air in their chest\n",
        " * *dta* - Double Trigger Asynchrony. Two breaths in a row where the patient is trapping air\n",
        " * *cough* - What it sounds like, when a patient coughs\n",
        " * *suction* -  Nurses perform suction procedures to remove excess fluid from an endotracheal tube. This waveform is indicative of that.\n",
        "\n",
        "Now that we understand what our columns are, we need to put it into a format where the machine can understand it and create a learning model. Because this is a multiclass model, let's just have __non-PVA breaths be class 0, breath stacking can be class 1, double trigger can be class 2__.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DCY16oHKxxY"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## Assignment \\#1 Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFr2IcciKxxZ"
      },
      "source": [
        "One thing to note is that we are using 16 different features for input into our model. Some of these features can be of little value to classifying whether a breath is asynchronous or not. So, one of the easiest things we can do for ourselves is to reduce the number of features that we have in an intelligent way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-SP0V3yKxxZ"
      },
      "source": [
        "### $\\chi^2$ Feature Selection (chi squared)\n",
        "\n",
        "Probably one of the easiest methods and intuitive methods to use for feature selection in classification problems. The [$\\chi^2$ test](https://en.wikipedia.org/wiki/Chi-squared_test) measures whether a two statistical distributions are independent. In t[he applied case](https://nlp.stanford.edu/IR-book/html/htmledition/feature-selectionchi2-feature-selection-1.html), this means asking the question of whether a single feature is independent of the target vector. If a feature and the outcome are independent then this variable might not be helpful for our model. If a feature is independent of the outcome it will have a high chi2 value and a high pvalue. On the other hand, if a feature is not independent of the outcome, then it will have a high chi2 value and a low p-value (within range of 0-.05).\n",
        "\n",
        "There is a function in scikit-learn that enables you to do the $\\chi^2$ test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POGQw_D2KxxZ",
        "outputId": "a3c97638-5d85-4d42-a5a1-1b9aee1f934f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(2.0845956610565963e-15, 'ep_auc'),\n",
            " (4.196362609415853e-10, 'tve'),\n",
            " (0.018753422526065044, 'i_time'),\n",
            " (0.05675212148048886, 'ip_auc'),\n",
            " (0.15346609771450123, 'max_pressure'),\n",
            " (0.41768345448124256, 'min_flow'),\n",
            " (0.4539978193631703, 'peep'),\n",
            " (0.6801265398971317, 'max_flow')]\n"
          ]
        }
      ],
      "source": [
        "# this is the PrettyPrint function. Just makes things look a bit nicer on output.\n",
        "from pprint import pprint\n",
        "\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# get all columns in our dataset except patient and breath_id\n",
        "columns_to_use = list(set(train_x.columns).difference(['patient', 'breath_id']))\n",
        "\n",
        "# must scale feature vectors so they are non-negative\n",
        "scaler = MinMaxScaler()\n",
        "train_set = scaler.fit_transform(train_x[columns_to_use])\n",
        "\n",
        "# the chi2 test will output two things, chi2 and p values. The p values are the most relevant item that we want\n",
        "# to use. A feature with a p-value between 0 and 0.05 means that a feature might be a good predictor of our outcome.\n",
        "chi2_vals, pvals = chi2(train_set, train_y_vector)\n",
        "\n",
        "# mash column names with p-values so we know which p-value belongs to which feature\n",
        "cols_to_pvals = zip(pvals, columns_to_use)\n",
        "# Sort the p-values in ascending order (smallest first).\n",
        "cols_sorted = sorted(cols_to_pvals)\n",
        "# pretty print the sorted values.\n",
        "pprint(cols_sorted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwzpIgrEKxxb"
      },
      "source": [
        "There are 2 features that had p-values below 0.05:\n",
        "\n",
        " * tve\n",
        " * ep_auc\n",
        "\n",
        "So let's use these features for our next model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3DhMwx8Kxxc",
        "outputId": "d4aa6046-acca-4757-b953-44ffb7943b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.79      0.77       842\n",
            "           1       0.42      0.48      0.45       301\n",
            "           2       0.06      0.02      0.03       104\n",
            "\n",
            "    accuracy                           0.65      1247\n",
            "   macro avg       0.41      0.43      0.42      1247\n",
            "weighted avg       0.62      0.65      0.63      1247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "columns_to_use = ['tve', 'ep_auc']\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_set = scaler.fit_transform(train_x[columns_to_use])\n",
        "test_set = scaler.transform(test_x[columns_to_use])\n",
        "\n",
        "model.fit(train_set, train_y_vector)\n",
        "predictions = model.predict(test_set)\n",
        "for idx, pred in enumerate(predictions):\n",
        "    if pred == 2:\n",
        "        predictions[idx-1] = 2\n",
        "\n",
        "print(classification_report(test_y_vector, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z79abeYmKxxi"
      },
      "source": [
        "Our performance actually dropped when we were trying to use $\\chi^2$ test. Does this mean that the $\\chi^2$ method isn't good for our problem?\n",
        "\n",
        "What is happening above?\n",
        "\n",
        "Even though the $\\chi^2$ test is telling us these features are relevant to prediction, this just isn't the case in  the test set. This can happen frequently in machine learning, where information that is relevant to the training set doesn't generalize to the testing set. Are there other methods of feature selection which are more likely to generalize to the testing set?\n",
        "\n",
        "### Expert Feature Selection\n",
        "\n",
        "It always helps to have expert knowledge on the problem to improve model performance. In this case expert knowledge can be considered medical knowledge. So what kind of medical knowledge can we use to help this?\n",
        "\n",
        "#### Breath Stack (BSA)\n",
        "Remember the waveforms here? This means that the patient is trapping air in their chest. We can measure this via the `tve_tvi_ratio`. The way that our doctors annotated breaths was if the breaths had a `tve_tvi_ratio < .9` and they weren't a suction/cough or another anomaly.\n",
        "\n",
        "<img src=\"bsa-breath.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
        "\n",
        "#### Double Trigger (DTA)\n",
        "Double trigger has a double-hump pattern to it.\n",
        "\n",
        "<img src=\"dta-breaths.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
        "\n",
        "The way our doctors annotated it was if\n",
        "\n",
        "1. It wasn't an anomaly\n",
        "2. First breath in sequence had an `e_time < .3` seconds\n",
        "3. First breath in sequence had `tve_tvi_ratio < .25` OR first breath had `0.25 <= tve_tvi_ratio < 0.5` and `tve < 100`\n",
        "\n",
        "Knowing this which features can we use here?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A_2Ieo1Kxxi"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier()\n",
        "\n",
        "# pick features based on expert selection. left for reader to determine best columns\n",
        "columns_to_use = []\n",
        "train_set = train_x[columns_to_use]\n",
        "test_set = test_x[columns_to_use]\n",
        "\n",
        "#model.fit(train_set, train_y_vector)\n",
        "#predictions = model.predict(test_set)\n",
        "#print(classification_report(test_y_vector, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rd3c4XwKxxk"
      },
      "source": [
        "### Other Methods\n",
        "\n",
        "You are welcome to use other methods / mathematical functions for feature selection as well. I will briefly outline some of them here.\n",
        "\n",
        "\n",
        "#### Wrapper Methods\n",
        "\n",
        "This performs feature selection by brute force. Using your validation set, train many models with every single possible feature combination you can have. Determination of which features work best can be chosen based on the best performing model. Then you can apply this model to your testing set to determine performance.\n",
        "\n",
        "Pros:\n",
        " * easy to understand\n",
        " * easy to code\n",
        "\n",
        "Cons:\n",
        " * prone to overfitting\n",
        " * is time consuming. Must train $n!$ models if $n$ is the number of features.\n",
        "\n",
        "#### PCA (Principal Component Analysis)\n",
        "\n",
        "This method utilizes the [principal component analysis algorithm](https://en.wikipedia.org/wiki/Principal_component_analysis) to transform your dataset and generate new features that are independent of each other. The user gets to choose the number of features that are generated, and often modelers choose to generate an increasing number of features, and then train a new model for each PCA run while determining the performance of each model.\n",
        "\n",
        "Pros:\n",
        " * Dimensionality reduction will cause models to train faster\n",
        " * Generated features are linearly uncorrelated with each other\n",
        " * Easy to utilize because there are multiple existing functions for this, like in [sckit-learn.](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n",
        "\n",
        "Cons:\n",
        " * Loss of information in your data will likely occur and may cause performance degradation\n",
        " * Human comprehension of features is lost when PCA is performed\n",
        "\n",
        "#### Mutual Information\n",
        "\n",
        "[Mutual Information](https://en.wikipedia.org/wiki/Mutual_information) is similar to $\\chi^2$ feature selection and measures the dependency between two variables. For machine learning this dependency can be measured between a feature and the target. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
        "\n",
        "Pros:\n",
        " * Fast\n",
        " * Supported by [Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html#r50b872b699c4-1)\n",
        "\n",
        "Cons:\n",
        " * Like $\\chi^2$ may not generalize to the test set.\n",
        "\n",
        "#### Mixed Methods\n",
        "\n",
        "It is possible use a variety of methods in combination with each other. Generally expert feature selection is the first method used and then additional synthetic methods are added on top of this. Ultimately as the modeler, this work is on you to figure out how to perform best. One method might work for one problem and then completely fail for another. This is why it is often best to utilize as many possible methods as possible when performing modeling and only declare a winner when all other possible methods have been explored. It is critical to always beware of overfitting. Have a good validation set to evaluate your model, and don't pick your best methods versus your testing set. This is almost guaranteed to lead to overfitting.\n",
        "\n",
        "### Finish Expert Feature Selection & Find another Feature Selection Method to Use.\n",
        "\n",
        "Finish the coding for expert feature selection and use another feature selection method like PCA/mutual information/wrapper methods for use in your model. Which one performs best?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5SJXb66Kxxl"
      },
      "outputs": [],
      "source": [
        "# XXX code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTo9ZiqS_Kns"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeQlqvtrKxxm"
      },
      "source": [
        "## Other Ways to Improve Your Model\n",
        "\n",
        "### Class Imbalance\n",
        "\n",
        "Class imbalance occurs when one class comprises a larger ratio of the observations in the dataset than another. This can be seen very clearly in our current training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNFP_mRjKxxn",
        "outputId": "d616feb6-f5aa-46e8-c696-9f5d6f3ff063"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    72.38781\n",
              "1    23.64367\n",
              "2     3.96852\n",
              "dtype: float64"
            ]
          },
          "execution_count": 35,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "|train_y_vector.value_counts() / len(train_y_vector) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYyxs9StKxxo"
      },
      "source": [
        "We can see here that normal observations comprise 72.3% of our training dataset, BSA is 19.68%, and DTA is 8.01%. This imbalance can have implications on the training of machine learning models because our model may not have enough information to learn effective class boundaries. Some algorithms are more resistant to class imbalance than others. Neural networks however are particularly affected by imbalance issues because of the nature of the way training is performed with these algorithms. Often algorithms besides neural networks benefit from techniques to reduce the class imbalance issue too. There are a number of techniques to tackle class imbalance.\n",
        "\n",
        "#### ROS (Random Over-Sampling)\n",
        "\n",
        "Random over-sampling aims to oversample minority classes by choosing observations at random with replacement until we  meet a certain ratio of majority to minority class observations. This is a fairly easy thing to code yourself if you wanted to do it, but just for ease we're going to use the [imbalanced-learn python package.](https://imbalanced-learn.readthedocs.io/en/stable/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLOJBsmmKxxp",
        "outputId": "44d82912-aa39-48ea-c775-fa76d348b3cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    4323\n",
              "1    4323\n",
              "0    4323\n",
              "dtype: int64"
            ]
          },
          "execution_count": 36,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import imblearn\n",
        "\n",
        "# get all columns in our dataset except patient and breath_id\n",
        "columns_to_use = list(set(train_x.columns).difference(['patient', 'breath_id']))\n",
        "# Initialize the RandomOverSampler. This initialization will give us 1:1:1 class ratios. If we want different\n",
        "# ratios then we can chance the sampling_strategy input argument. For more details see the documentation\n",
        "# https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler\n",
        "ros = imblearn.over_sampling.RandomOverSampler()\n",
        "# re-sample the train set ONLY. Don't resample the testing set because otherwise you would be biasing model conclusions\n",
        "train_x_ros, train_y_ros = ros.fit_resample(train_x[columns_to_use], train_y_vector)\n",
        "\n",
        "# put the target vector into a series so we can just do some convenience function.\n",
        "train_y_ros = pd.Series(train_y_ros)\n",
        "# You'll see the dataset is equilibrated now with equal observations normal, BSA, and DTA breaths.\n",
        "train_y_ros.value_counts()\n",
        "\n",
        "# Now we can put this back into our model and see if performance changes. This is left for the reader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBmeV_-PKxxr"
      },
      "source": [
        "#### RUS (Random Under-Sampling)\n",
        "\n",
        "![](over-sampling-undersampling.png)\n",
        "\n",
        "Random under-sampling is basically the inverse of the over-sampling technique. Instead of selecting with replacement from minority classes, here we randomly sample from the majority classes only until they meet some class ratio with the minority classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AmL8yxjKxxs",
        "outputId": "937b2440-4dd5-4c27-d2de-3285782fcb79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    237\n",
              "1    237\n",
              "0    237\n",
              "dtype: int64"
            ]
          },
          "execution_count": 37,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import imblearn\n",
        "\n",
        "# get all columns in our dataset except patient and breath_id\n",
        "columns_to_use = list(set(train_x.columns).difference(['patient', 'breath_id']))\n",
        "# Initialize the RandomUnderSampler. This initialization will give us 1:1:1 class ratios. If we want different\n",
        "# ratios then we can chance the sampling_strategy input argument. For more details see the documentation\n",
        "# https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.RandomUnderSampler.html#imblearn.under_sampling.RandomUnderSampler\n",
        "rus = imblearn.under_sampling.RandomUnderSampler()\n",
        "# re-sample the train set ONLY. Don't resample the testing set because otherwise you would be biasing model conclusions\n",
        "train_x_rus, train_y_rus = rus.fit_resample(train_x[columns_to_use], train_y_vector)\n",
        "\n",
        "# put the target vector into a series so we can just do some convenience function.\n",
        "train_y_rus = pd.Series(train_y_rus)\n",
        "# You'll see the dataset is equilibrated now with equal observations normal, BSA, and DTA breaths.\n",
        "train_y_rus.value_counts()\n",
        "\n",
        "# Now we can put this back into our model and see if performance changes. This is left for the reader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNTlpc7TKxxu"
      },
      "source": [
        "There are some downsides to RUS in that we are discarding data from the majority class which might be useful for the future. Also if some classes have very low ratios of data relative to the majority class then RUS may have more limited utility. With RUS, as with ROS, we will need to evaluate the effect of different class ratios on our validation set. Maybe a `4:2:1` ratio would be best for this problem, we just don't know until we try. I will leave this as an additional exercise for the reader.\n",
        "\n",
        "#### SMOTE (Synthetic Minority Oversampling TEchnique)\n",
        "\n",
        "One downside about the methods mentioned is that they always are drawn from the existing distribution of class data. It is quite possible that if we collected additional samples that there would be new observations that fit in between these existing data points. This is the intuition behind smote that can also be seen in the below image.\n",
        "\n",
        "![](smote-intuition.png)\n",
        "\n",
        "The benefit of SMOTE is that we are expanding our dataset, which means more data for our model to train on, while we are semi-intelligently generating new samples. Of course generated data may have no basis for reality, so good modeling habit should always check to see whether RUS, ROS, or SMOTE works best for a problem, and which class ratios work best for which technique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6EIip_zKxxu",
        "outputId": "607378d7-06e2-4b81-deaa-383eefcbc109"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    4323\n",
              "1    4323\n",
              "0    4323\n",
              "dtype: int64"
            ]
          },
          "execution_count": 38,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import imblearn\n",
        "\n",
        "# get all columns in our dataset except patient and breath_id\n",
        "columns_to_use = list(set(train_x.columns).difference(['patient', 'breath_id']))\n",
        "# Initialize SMOTE. This initialization will give us 1:1:1 class ratios. If we want different\n",
        "# ratios then we can chance the sampling_strategy input argument. For more details see the documentation\n",
        "# https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE\n",
        "smote = imblearn.over_sampling.SMOTE()\n",
        "# re-sample the train set ONLY. Don't resample the testing set because otherwise you would be biasing model conclusions\n",
        "train_x_smote, train_y_smote = smote.fit_resample(train_x[columns_to_use], train_y_vector)\n",
        "\n",
        "# put the target vector into a series so we can just do some convenience function.\n",
        "train_y_smote = pd.Series(train_y_smote)\n",
        "# You'll see the dataset is equilibrated now with equal observations normal, BSA, and DTA breaths.\n",
        "train_y_smote.value_counts()\n",
        "# Now we can put this back into our model and see if performance changes. This is left for the reader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL8JjUwNKxxy"
      },
      "source": [
        "## Assignment \\#2 Utilize all 3 Imbalance Correction Techniques\n",
        "\n",
        "Utilize ROS, RUS, and SMOTE with the following imbalance ratios: 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0. Is there an algorithm that performs best? Are there ratios of imbalance that perform best?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSSdsqqfKxxy"
      },
      "outputs": [],
      "source": [
        "# Example code for creating 0.3 imbalance ratio. The same parameters will work for ROS and RUS functions too.\n",
        "\n",
        "smote = imblearn.over_sampling.SMOTE(sampling_strategy=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCRfvt-2_Knu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to Systematically Evaluate Your Model\n",
        "\n",
        "### k-fold cross-validation\n",
        "\n",
        "K-fold cross-validation is a resampling procedure used to systematically evaluate machine learning models. The procedure has a parameter called k that refers to the number of groups that a given data sample is to be split into. This technique is important in machine learning because it ensures that every observation from the original dataset has the chance of appearing in the training and test set, providing a thorough assessment of how well a model performs across different subsets of data."
      ],
      "metadata": {
        "id": "vClSYCkRK3Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "##Define k\n",
        "k = 5\n",
        "\n",
        "##initialize k fold setup for cross-validation\n",
        "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "HwqrVlLRL-9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remember your train_set_scaled must be already defined from Pre-Lab!\n",
        "\n",
        "##Choose your model\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "for train_index, val_index in kf.split(train_set_scaled, train_y_vector):\n",
        "\n",
        "      X_train, X_val = train_set_scaled[train_index], train_set_scaled[val_index]\n",
        "      y_train, y_val = train_y_vector[train_index], train_y_vector[val_index]\n",
        "\n",
        "      # Now we can fit the model, generate predictions, and compare the performance with validation labels y_val.\n",
        "      # Once that is done, we save the results for next fold/iteration"
      ],
      "metadata": {
        "id": "nVirnCWgMEzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment \\#3 Perform k-fold cross-validation\n",
        "\n",
        "Evaluate an ML model of your choosing (RF, Logistic Regression, etc...) under 5-fold cross-validation. Print the macro average precision, recall, and f1-scores in each fold. Print the average values across all 5 folds at the end of the loop."
      ],
      "metadata": {
        "id": "1Bvejrq7JxIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XXX code here"
      ],
      "metadata": {
        "id": "sr8Ex01dQcJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the tutorial, you are taught to use the function StratifiedKFold. What does it mean when we stratify our k-folds?"
      ],
      "metadata": {
        "id": "QXi4ptRdSZnF"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}