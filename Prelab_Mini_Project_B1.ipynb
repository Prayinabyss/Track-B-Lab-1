{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62gkk4_lKztu"
      },
      "source": [
        "# EEC 174AY 2023 Fall Pre-lab B1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc654drGKztv"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NYkq2beKztw"
      },
      "source": [
        "This asignment follows Lab2 and uses the same dataset as Lab2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBtNuNPcKztx"
      },
      "source": [
        "### Reading Data into Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WKZVXLZfKztx"
      },
      "outputs": [],
      "source": [
        "# make sure we can plot in future if we want\n",
        "%matplotlib notebook\n",
        "# make sure to ignore warnings\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "# Import statement for pandas\n",
        "import pandas as pd\n",
        "# This is just a small configuration change for purposes of the class\n",
        "pd.options.display.max_rows = 10\n",
        "\n",
        "# Get our train X and y datasets for the problem\n",
        "train_x = pd.read_csv('ece174_pva_train_x.csv')\n",
        "train_y = pd.read_csv('ece174_pva_train_y.csv')\n",
        "\n",
        "# Get our validation X and y datasets for the problem.\n",
        "test_x = pd.read_csv('ece174_pva_validation_x.csv')\n",
        "test_y = pd.read_csv('ece174_pva_validation_y.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mRttEP9VKzt0",
        "outputId": "e05f6f7b-5145-4aee-a987-5bc1ac281680"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breath_id</th>\n",
              "      <th>i_time</th>\n",
              "      <th>tve</th>\n",
              "      <th>max_flow</th>\n",
              "      <th>min_flow</th>\n",
              "      <th>max_pressure</th>\n",
              "      <th>peep</th>\n",
              "      <th>ip_auc</th>\n",
              "      <th>ep_auc</th>\n",
              "      <th>patient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "      <td>545.032222</td>\n",
              "      <td>51.06</td>\n",
              "      <td>-41.03</td>\n",
              "      <td>17.37</td>\n",
              "      <td>7.600</td>\n",
              "      <td>11.122367</td>\n",
              "      <td>16.057733</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.80</td>\n",
              "      <td>531.880278</td>\n",
              "      <td>53.13</td>\n",
              "      <td>-39.97</td>\n",
              "      <td>17.13</td>\n",
              "      <td>7.508</td>\n",
              "      <td>11.077750</td>\n",
              "      <td>17.310533</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.86</td>\n",
              "      <td>523.876667</td>\n",
              "      <td>52.86</td>\n",
              "      <td>-38.24</td>\n",
              "      <td>17.11</td>\n",
              "      <td>7.658</td>\n",
              "      <td>12.066000</td>\n",
              "      <td>16.697800</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.80</td>\n",
              "      <td>507.636111</td>\n",
              "      <td>51.04</td>\n",
              "      <td>-39.37</td>\n",
              "      <td>17.14</td>\n",
              "      <td>7.572</td>\n",
              "      <td>11.097800</td>\n",
              "      <td>15.774250</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.80</td>\n",
              "      <td>518.618889</td>\n",
              "      <td>47.88</td>\n",
              "      <td>-38.51</td>\n",
              "      <td>16.92</td>\n",
              "      <td>7.598</td>\n",
              "      <td>11.065400</td>\n",
              "      <td>18.483333</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5970</th>\n",
              "      <td>296</td>\n",
              "      <td>0.90</td>\n",
              "      <td>355.365278</td>\n",
              "      <td>42.26</td>\n",
              "      <td>-51.51</td>\n",
              "      <td>23.53</td>\n",
              "      <td>13.194</td>\n",
              "      <td>19.216400</td>\n",
              "      <td>21.816367</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5971</th>\n",
              "      <td>297</td>\n",
              "      <td>0.90</td>\n",
              "      <td>316.806944</td>\n",
              "      <td>42.10</td>\n",
              "      <td>-55.17</td>\n",
              "      <td>24.61</td>\n",
              "      <td>12.896</td>\n",
              "      <td>19.800467</td>\n",
              "      <td>21.739700</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5972</th>\n",
              "      <td>298</td>\n",
              "      <td>0.92</td>\n",
              "      <td>395.971111</td>\n",
              "      <td>42.95</td>\n",
              "      <td>-22.47</td>\n",
              "      <td>21.35</td>\n",
              "      <td>13.090</td>\n",
              "      <td>16.997767</td>\n",
              "      <td>21.457600</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5973</th>\n",
              "      <td>299</td>\n",
              "      <td>0.90</td>\n",
              "      <td>373.426389</td>\n",
              "      <td>40.34</td>\n",
              "      <td>-36.81</td>\n",
              "      <td>21.69</td>\n",
              "      <td>13.334</td>\n",
              "      <td>17.944000</td>\n",
              "      <td>21.798167</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5974</th>\n",
              "      <td>300</td>\n",
              "      <td>0.90</td>\n",
              "      <td>364.684444</td>\n",
              "      <td>42.29</td>\n",
              "      <td>-45.94</td>\n",
              "      <td>22.69</td>\n",
              "      <td>13.002</td>\n",
              "      <td>18.679800</td>\n",
              "      <td>21.801950</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5975 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      breath_id  i_time         tve  max_flow  min_flow  max_pressure    peep  \\\n",
              "0             1    0.80  545.032222     51.06    -41.03         17.37   7.600   \n",
              "1             2    0.80  531.880278     53.13    -39.97         17.13   7.508   \n",
              "2             3    0.86  523.876667     52.86    -38.24         17.11   7.658   \n",
              "3             4    0.80  507.636111     51.04    -39.37         17.14   7.572   \n",
              "4             5    0.80  518.618889     47.88    -38.51         16.92   7.598   \n",
              "...         ...     ...         ...       ...       ...           ...     ...   \n",
              "5970        296    0.90  355.365278     42.26    -51.51         23.53  13.194   \n",
              "5971        297    0.90  316.806944     42.10    -55.17         24.61  12.896   \n",
              "5972        298    0.92  395.971111     42.95    -22.47         21.35  13.090   \n",
              "5973        299    0.90  373.426389     40.34    -36.81         21.69  13.334   \n",
              "5974        300    0.90  364.684444     42.29    -45.94         22.69  13.002   \n",
              "\n",
              "         ip_auc     ep_auc  patient  \n",
              "0     11.122367  16.057733       66  \n",
              "1     11.077750  17.310533       66  \n",
              "2     12.066000  16.697800       66  \n",
              "3     11.097800  15.774250       66  \n",
              "4     11.065400  18.483333       66  \n",
              "...         ...        ...      ...  \n",
              "5970  19.216400  21.816367      662  \n",
              "5971  19.800467  21.739700      662  \n",
              "5972  16.997767  21.457600      662  \n",
              "5973  17.944000  21.798167      662  \n",
              "5974  18.679800  21.801950      662  \n",
              "\n",
              "[5975 rows x 10 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# output some rows of the dataset just to get a better feel for the information\n",
        "train_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mznyk0N3Kzt4"
      },
      "source": [
        "Here we have 18 columns. I'm going to give a detailed breakdown here. Feel free to come back to it as necessary.\n",
        "\n",
        "Features:\n",
        " * *breath_id* - matches with a specific breath identifier from the raw data file.\n",
        " * *patient* - the patient the data came from\n",
        " * *min_flow* - The minimum flow observation on the breath\n",
        " * *max_flow* - The maximum flow observation on the breath\n",
        " * *tvi* - The inhaled volume of air for each breath\n",
        " * *tve* - The exhaled volume of air for each breath\n",
        " * *tve_tvi_ratio* - The ratio of `tve / tvi`\n",
        " * *i_time* - The amount of time patient was breathing in for each breath\n",
        " * *e_time* - The amount of time patient was breathing out for each breath\n",
        " * *ie_ratio* - The ratio of `i_time / e_time`\n",
        " * *rr* - The respiratory rate in number of breaths per minute. Measured by `60 / (i_time + e_time)`\n",
        " * *min_pressure* - the minimum pressure observation on the breath\n",
        " * *max_pressure* - the maximum pressure observation on the breath\n",
        " * *peep* - the baseline pressure setting on the ventilator\n",
        " * *pip* - the maximum pressure setting of inspiration. Slight difference compared to max_pressure\n",
        " * *maw* - the mean pressure for the entire breath\n",
        " * *ip_auc* - the area under the curve of the inspiratory pressure\n",
        " * *ep_auc* - the area under the curve of the expiratory pressure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOjD7m2NKzt5"
      },
      "source": [
        "## Featurization\n",
        "\n",
        "Featurization is the process where you extract information from raw data. This information can then be fed into a machine learning algorithm to perform the task you want. In the current case we will need to extract additional information from the ventilator data in order to create a valid machine learning classifier.\n",
        "\n",
        "### Processing the Data\n",
        "The first step we need to do is to be able to read the raw data files and put them into memory. We have taken this problem away from you for the purposes of this homework and have given you the code so that you can do this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZVmOloDxKzt5"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "def process_ventilator_data(filename):\n",
        "    descriptor = open(filename)\n",
        "    reader = csv.reader(descriptor)\n",
        "    breath_id = 1\n",
        "\n",
        "    all_breath_data = []\n",
        "    current_flow_data = []\n",
        "    current_pressure_data = []\n",
        "\n",
        "    for row in reader:\n",
        "        if (row[0].strip() == 'BS' or row[0].strip() == 'BE') and current_flow_data != []:\n",
        "            all_breath_data.append({'breath_id': breath_id, 'flow': current_flow_data, 'pressure': current_pressure_data})\n",
        "            breath_id += 1\n",
        "            current_flow_data = []\n",
        "            current_pressure_data = []\n",
        "        else:\n",
        "            try:\n",
        "                current_flow_data.append(round(float(row[0]), 2))\n",
        "                current_pressure_data.append(round(float(row[1]), 2))\n",
        "            except (IndexError, ValueError):\n",
        "                continue\n",
        "    return all_breath_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MRcI4TUWKzt8"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import os\n",
        "\n",
        "# import for Simpson's method. This will be helpful for calculating TVi\n",
        "from scipy.integrate import simps\n",
        "from statistics import mean\n",
        "\n",
        "\n",
        "def extract_features_for_file(filename, existing_features):\n",
        "    \"\"\"\n",
        "    Extract features for every single breath in file. To make matters a bit easier, we use\n",
        "    existing features that we've already extracted from the file to help speed the process.\n",
        "    \"\"\"\n",
        "    patient = filename.split('\\\\')[-2]\n",
        "    all_breath_data = process_ventilator_data(filename)\n",
        "    all_features = []\n",
        "\n",
        "    for breath_data in all_breath_data:\n",
        "        breath_id = breath_data['breath_id']\n",
        "        existing_breath_features = existing_features[existing_features.breath_id == breath_id].iloc[0]\n",
        "\n",
        "        flow = breath_data['flow']\n",
        "        pressure = breath_data['pressure']\n",
        "\n",
        "        # inspiratory time (the amount of time a patient is inhaling for)\n",
        "        i_time = existing_breath_features.i_time\n",
        "        # exhaled tidal volume\n",
        "        tve = existing_breath_features.tve\n",
        "        # maximum flow for breath\n",
        "        max_flow = existing_breath_features.max_flow\n",
        "        # minimum flow for the breath\n",
        "        min_flow = existing_breath_features.min_flow\n",
        "        # maximum pressure for the breath\n",
        "        max_pressure = existing_breath_features.max_pressure\n",
        "        # The minimum pressure setting on the ventilator\n",
        "        peep = existing_breath_features.peep\n",
        "        # The area under the curve of the inspiratory pressure curve\n",
        "        ip_auc = existing_breath_features.ip_auc\n",
        "        # The area under the curve of the expiratory pressure curve\n",
        "        ep_auc = existing_breath_features.ep_auc\n",
        "\n",
        "        # This is the array index where the inhalation ends. We divide by 0.02 because\n",
        "        # thats how frequently the ventilator samples data, every 0.02 seconds.\n",
        "        x0_index = int(i_time / 0.02)\n",
        "\n",
        "        # Part of your assignment is to extract the following features for all breaths:\n",
        "        #\n",
        "        # Expiratory Time. The amount of time a patient is exhaling\n",
        "        e_time = len(flow) * .02 - i_time\n",
        "        #\n",
        "        # I:E ratio. The ratio of inspiratory to expiratory time. Measured by i_time/e_time\n",
        "        i_e_ratio = i_time / e_time\n",
        "        #\n",
        "        # Respiratory rate. The number of breaths a patient is breathing. This is measured by\n",
        "        # 60 / (total breath time in seconds)\n",
        "        rr = 60 / (i_time + e_time)\n",
        "        rr = 60 / (len(flow) * .02)\n",
        "        #\n",
        "        # Tidal volume inhaled. The amount of air volume inhaled in the breath.\n",
        "        # Hint: use the simps function.\n",
        "        # This will output volume in L/min, convert to ml/sec (* 1000 / 60)\n",
        "        tvi = simps(flow[:x0_index], dx=0.02) * 1000 / 60\n",
        "        #\n",
        "        # Tidal volume ratio. Measured by tve/tvi\n",
        "        tve_tvi_ratio = tve / tvi\n",
        "        #\n",
        "        # Minimum pressure of the breath\n",
        "        min_pressure = min(pressure)\n",
        "        #\n",
        "        # PIP - peak inspiratory pressure. The peak pressure during inhalation\n",
        "        pip = max(pressure[:x0_index])\n",
        "        #\n",
        "        # MAW - mean airway pressure for inhalation.\n",
        "        maw = mean(pressure[:x0_index])\n",
        "\n",
        "        all_features.append([\n",
        "            breath_id, i_time, e_time, i_e_ratio, rr, tvi, tve, tve_tvi_ratio,\n",
        "            max_flow, min_flow, max_pressure, min_pressure, pip, maw,\n",
        "            peep, ip_auc, ep_auc, int(patient)\n",
        "        ])\n",
        "    columns = [\n",
        "        'breath_id', 'i_time', 'e_time', 'i_e_ratio', 'rr', 'tvi', 'tve',\n",
        "        'tve_tvi_ratio', 'max_flow', 'min_flow', 'max_pressure',\n",
        "        'min_pressure', 'pip', 'maw', 'peep', 'ip_auc', 'ep_auc', 'patient'\n",
        "    ]\n",
        "    return all_features, columns\n",
        "\n",
        "\n",
        "def remake_dataset(dataset):\n",
        "    data_files = glob(os.path.join('data', '*/*.csv'))\n",
        "\n",
        "    patient_to_file_map = {}\n",
        "    for filename in data_files:\n",
        "        patient = filename.split('\\\\')[-2]  # patient is embedded in this part of filename\n",
        "        patient_to_file_map[patient] = filename\n",
        "\n",
        "    data = []\n",
        "    # iterate over all the unique patients in the train set\n",
        "    for patient in dataset.patient.unique():\n",
        "        existing_features = dataset[dataset.patient == patient]\n",
        "        filename = patient_to_file_map[str(patient)]\n",
        "        breath_data, columns = extract_features_for_file(filename, existing_features)\n",
        "        # add breath rows\n",
        "        data.extend(breath_data)\n",
        "    # create new data frame with the new added information\n",
        "    return pd.DataFrame(data, columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SIFPJtktKzt-"
      },
      "outputs": [],
      "source": [
        "# remake train set\n",
        "train_x = remake_dataset(train_x)\n",
        "# remake validation set.\n",
        "test_x = remake_dataset(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Xnjp0FmuKzuA",
        "outputId": "44336221-6fe4-42bf-a7be-4b7155991b50"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breath_id</th>\n",
              "      <th>i_time</th>\n",
              "      <th>e_time</th>\n",
              "      <th>i_e_ratio</th>\n",
              "      <th>rr</th>\n",
              "      <th>tvi</th>\n",
              "      <th>tve</th>\n",
              "      <th>tve_tvi_ratio</th>\n",
              "      <th>max_flow</th>\n",
              "      <th>min_flow</th>\n",
              "      <th>max_pressure</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>pip</th>\n",
              "      <th>maw</th>\n",
              "      <th>peep</th>\n",
              "      <th>ip_auc</th>\n",
              "      <th>ep_auc</th>\n",
              "      <th>patient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.66</td>\n",
              "      <td>0.481928</td>\n",
              "      <td>24.390244</td>\n",
              "      <td>481.917778</td>\n",
              "      <td>545.032222</td>\n",
              "      <td>1.130965</td>\n",
              "      <td>51.06</td>\n",
              "      <td>-41.03</td>\n",
              "      <td>17.37</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.37</td>\n",
              "      <td>14.208500</td>\n",
              "      <td>7.600</td>\n",
              "      <td>11.122367</td>\n",
              "      <td>16.057733</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>484.920278</td>\n",
              "      <td>531.880278</td>\n",
              "      <td>1.096841</td>\n",
              "      <td>53.13</td>\n",
              "      <td>-39.97</td>\n",
              "      <td>17.13</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.13</td>\n",
              "      <td>14.149500</td>\n",
              "      <td>7.508</td>\n",
              "      <td>11.077750</td>\n",
              "      <td>17.310533</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.74</td>\n",
              "      <td>0.494253</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>521.370000</td>\n",
              "      <td>523.876667</td>\n",
              "      <td>1.004808</td>\n",
              "      <td>52.86</td>\n",
              "      <td>-38.24</td>\n",
              "      <td>17.11</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.11</td>\n",
              "      <td>14.311860</td>\n",
              "      <td>7.658</td>\n",
              "      <td>12.066000</td>\n",
              "      <td>16.697800</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.64</td>\n",
              "      <td>0.487805</td>\n",
              "      <td>24.590164</td>\n",
              "      <td>482.908333</td>\n",
              "      <td>507.636111</td>\n",
              "      <td>1.051206</td>\n",
              "      <td>51.04</td>\n",
              "      <td>-39.37</td>\n",
              "      <td>17.14</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.14</td>\n",
              "      <td>14.174500</td>\n",
              "      <td>7.572</td>\n",
              "      <td>11.097800</td>\n",
              "      <td>15.774250</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.94</td>\n",
              "      <td>0.412371</td>\n",
              "      <td>21.897810</td>\n",
              "      <td>466.349722</td>\n",
              "      <td>518.618889</td>\n",
              "      <td>1.112081</td>\n",
              "      <td>47.88</td>\n",
              "      <td>-38.51</td>\n",
              "      <td>16.92</td>\n",
              "      <td>7.04</td>\n",
              "      <td>16.92</td>\n",
              "      <td>14.131250</td>\n",
              "      <td>7.598</td>\n",
              "      <td>11.065400</td>\n",
              "      <td>18.483333</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5970</th>\n",
              "      <td>296</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>349.682222</td>\n",
              "      <td>355.365278</td>\n",
              "      <td>1.016252</td>\n",
              "      <td>42.26</td>\n",
              "      <td>-51.51</td>\n",
              "      <td>23.53</td>\n",
              "      <td>13.00</td>\n",
              "      <td>23.53</td>\n",
              "      <td>21.750667</td>\n",
              "      <td>13.194</td>\n",
              "      <td>19.216400</td>\n",
              "      <td>21.816367</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5971</th>\n",
              "      <td>297</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>350.130000</td>\n",
              "      <td>316.806944</td>\n",
              "      <td>0.904827</td>\n",
              "      <td>42.10</td>\n",
              "      <td>-55.17</td>\n",
              "      <td>24.61</td>\n",
              "      <td>12.80</td>\n",
              "      <td>24.61</td>\n",
              "      <td>22.414667</td>\n",
              "      <td>12.896</td>\n",
              "      <td>19.800467</td>\n",
              "      <td>21.739700</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5972</th>\n",
              "      <td>298</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1.58</td>\n",
              "      <td>0.582278</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>355.670278</td>\n",
              "      <td>395.971111</td>\n",
              "      <td>1.113310</td>\n",
              "      <td>42.95</td>\n",
              "      <td>-22.47</td>\n",
              "      <td>21.35</td>\n",
              "      <td>12.90</td>\n",
              "      <td>21.35</td>\n",
              "      <td>18.785435</td>\n",
              "      <td>13.090</td>\n",
              "      <td>16.997767</td>\n",
              "      <td>21.457600</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5973</th>\n",
              "      <td>299</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>337.941111</td>\n",
              "      <td>373.426389</td>\n",
              "      <td>1.105004</td>\n",
              "      <td>40.34</td>\n",
              "      <td>-36.81</td>\n",
              "      <td>21.69</td>\n",
              "      <td>13.02</td>\n",
              "      <td>21.69</td>\n",
              "      <td>20.308444</td>\n",
              "      <td>13.334</td>\n",
              "      <td>17.944000</td>\n",
              "      <td>21.798167</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5974</th>\n",
              "      <td>300</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>342.556667</td>\n",
              "      <td>364.684444</td>\n",
              "      <td>1.064596</td>\n",
              "      <td>42.29</td>\n",
              "      <td>-45.94</td>\n",
              "      <td>22.69</td>\n",
              "      <td>12.90</td>\n",
              "      <td>22.69</td>\n",
              "      <td>21.145778</td>\n",
              "      <td>13.002</td>\n",
              "      <td>18.679800</td>\n",
              "      <td>21.801950</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5975 rows Ã— 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      breath_id  i_time  e_time  i_e_ratio         rr         tvi         tve  \\\n",
              "0             1    0.80    1.66   0.481928  24.390244  481.917778  545.032222   \n",
              "1             2    0.80    1.80   0.444444  23.076923  484.920278  531.880278   \n",
              "2             3    0.86    1.74   0.494253  23.076923  521.370000  523.876667   \n",
              "3             4    0.80    1.64   0.487805  24.590164  482.908333  507.636111   \n",
              "4             5    0.80    1.94   0.412371  21.897810  466.349722  518.618889   \n",
              "...         ...     ...     ...        ...        ...         ...         ...   \n",
              "5970        296    0.90    1.60   0.562500  24.000000  349.682222  355.365278   \n",
              "5971        297    0.90    1.60   0.562500  24.000000  350.130000  316.806944   \n",
              "5972        298    0.92    1.58   0.582278  24.000000  355.670278  395.971111   \n",
              "5973        299    0.90    1.60   0.562500  24.000000  337.941111  373.426389   \n",
              "5974        300    0.90    1.60   0.562500  24.000000  342.556667  364.684444   \n",
              "\n",
              "      tve_tvi_ratio  max_flow  min_flow  max_pressure  min_pressure    pip  \\\n",
              "0          1.130965     51.06    -41.03         17.37          7.04  17.37   \n",
              "1          1.096841     53.13    -39.97         17.13          7.04  17.13   \n",
              "2          1.004808     52.86    -38.24         17.11          7.04  17.11   \n",
              "3          1.051206     51.04    -39.37         17.14          7.04  17.14   \n",
              "4          1.112081     47.88    -38.51         16.92          7.04  16.92   \n",
              "...             ...       ...       ...           ...           ...    ...   \n",
              "5970       1.016252     42.26    -51.51         23.53         13.00  23.53   \n",
              "5971       0.904827     42.10    -55.17         24.61         12.80  24.61   \n",
              "5972       1.113310     42.95    -22.47         21.35         12.90  21.35   \n",
              "5973       1.105004     40.34    -36.81         21.69         13.02  21.69   \n",
              "5974       1.064596     42.29    -45.94         22.69         12.90  22.69   \n",
              "\n",
              "            maw    peep     ip_auc     ep_auc  patient  \n",
              "0     14.208500   7.600  11.122367  16.057733       66  \n",
              "1     14.149500   7.508  11.077750  17.310533       66  \n",
              "2     14.311860   7.658  12.066000  16.697800       66  \n",
              "3     14.174500   7.572  11.097800  15.774250       66  \n",
              "4     14.131250   7.598  11.065400  18.483333       66  \n",
              "...         ...     ...        ...        ...      ...  \n",
              "5970  21.750667  13.194  19.216400  21.816367      662  \n",
              "5971  22.414667  12.896  19.800467  21.739700      662  \n",
              "5972  18.785435  13.090  16.997767  21.457600      662  \n",
              "5973  20.308444  13.334  17.944000  21.798167      662  \n",
              "5974  21.145778  13.002  18.679800  21.801950      662  \n",
              "\n",
              "[5975 rows x 18 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilPoq-riKzuD"
      },
      "source": [
        "### Create Ground Truth (that the machine understands)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CZyvPnXVKzuE",
        "outputId": "cb746889-51e6-46f0-f1e4-3231901b4ad4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breath_id</th>\n",
              "      <th>patient</th>\n",
              "      <th>bsa</th>\n",
              "      <th>dta</th>\n",
              "      <th>cough</th>\n",
              "      <th>suction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>292</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1242</th>\n",
              "      <td>295</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1243</th>\n",
              "      <td>296</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1244</th>\n",
              "      <td>297</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1245</th>\n",
              "      <td>298</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1246</th>\n",
              "      <td>299</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1247 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      breath_id  patient  bsa  dta  cough  suction\n",
              "0            20      292    1    0      0        0\n",
              "1            21      292    1    0      0        0\n",
              "2            22      292    0    0      0        0\n",
              "3            23      292    1    0      0        0\n",
              "4            24      292    1    0      0        0\n",
              "...         ...      ...  ...  ...    ...      ...\n",
              "1242        295      114    0    0      0        0\n",
              "1243        296      114    0    0      0        0\n",
              "1244        297      114    0    0      0        0\n",
              "1245        298      114    0    0      0        0\n",
              "1246        299      114    0    0      0        0\n",
              "\n",
              "[1247 rows x 6 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read the test dataset and set it up. Technically we're using the validation set.\n",
        "test_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtS2Cl7NKzuG"
      },
      "source": [
        "What does this mean?\n",
        "\n",
        "We have 6 columns here\n",
        " * *breath_id* - matches with a specific breath identifier from the raw data file.\n",
        " * *patient* - the patient the data came from\n",
        " * *bsa* - Breath Stacking Asynchrony. A single breath where the patient is trapping air in their chest\n",
        " * *dta* - Double Trigger Asynchrony. Two breaths in a row where the patient is trapping air\n",
        " * *cough* - What it sounds like, when a patient coughs\n",
        " * *suction* -  Nurses perform suction procedures to remove excess fluid from an endotracheal tube. This waveform is indicative of that.\n",
        "\n",
        "Now that we understand what our columns are, we need to put it into a format where the machine can understand it and create a learning model. Because this is a multiclass model, let's just have non-PVA breaths be class 0, breath stacking can be class 1, double trigger can be class 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zE44UfwtKzuG",
        "outputId": "68fede4c-4368-452f-f70c-2b61548af3a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       0\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "1242    0\n",
              "1243    0\n",
              "1244    0\n",
              "1245    0\n",
              "1246    0\n",
              "Length: 1247, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a multi-class y vector that we can use for training purposes.\n",
        "train_y_vector = train_y.bsa * 1 + train_y.dta * 2\n",
        "test_y_vector = test_y.bsa * 1 + test_y.dta * 2\n",
        "test_y_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qzrRJ5-SKzuJ",
        "outputId": "ef2dea76-f6c2-448d-81e5-46c47a172adf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5438    3\n",
              "5440    3\n",
              "5521    3\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# See if there places where the data was mis-annotated, where both double trigger and breath stack was annotated.\n",
        "# It's just good to know if this is happening or not so that we can either drop the data, or change it later on.\n",
        "train_y_vector[train_y_vector > 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8FoDLUZKzuM"
      },
      "source": [
        "### Creating a Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Th1VdBy0KzuM"
      },
      "outputs": [],
      "source": [
        "# Need to finalize dataset and remove misannotated examples first.\n",
        "\n",
        "# just drop places where data is double annotated.\n",
        "misannotated_train = train_y_vector > 2\n",
        "misannotated_test = test_y_vector > 2\n",
        "\n",
        "# ~ is the NOT operator\n",
        "train_x = train_x.loc[~misannotated_train]\n",
        "train_y_vector = train_y_vector.loc[~misannotated_train]\n",
        "\n",
        "# do same thing for test\n",
        "test_x = test_x.loc[~misannotated_test]\n",
        "test_y_vector = test_y_vector.loc[~misannotated_test]\n",
        "\n",
        "\n",
        "\n",
        "# Also make sure to drop data that is NaN. This is very important because otherwise your model won't train.\n",
        "# The .any(axis=1) function basically says, if there are any nans in this *ROW* then mark the row as true.\n",
        "# The .any(axis=0) would mark columns as True/False, but this isn't helpful now.\n",
        "nans_train = train_x.isna().any(axis=1)\n",
        "nans_test = test_x.isna().any(axis=1)\n",
        "\n",
        "# now filter them out of the dataset in the same way\n",
        "train_x = train_x.loc[~nans_train]\n",
        "train_y_vector = train_y_vector.loc[~nans_train]\n",
        "\n",
        "test_x = test_x.loc[~nans_test]\n",
        "test_y_vector = test_y_vector.loc[~nans_test]\n",
        "\n",
        "\n",
        "# any time we drop things from a data frame or series in pandas it is often helpful to re-index the object.\n",
        "# the index is usually a sequential ordering of the rows like 1, 2, ... n. Sometimes it can be different\n",
        "# but for now we'll just use sequential ordering\n",
        "train_x.index = range(len(train_x))\n",
        "train_y_vector.index = range(len(train_y_vector))\n",
        "\n",
        "test_x.index = range(len(test_x))\n",
        "test_y_vector.index = range(len(test_y_vector))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PCCAgbrGKzuP",
        "outputId": "e5a501b8-42b8-4686-93cb-eb528aebf654"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breath_id</th>\n",
              "      <th>i_time</th>\n",
              "      <th>e_time</th>\n",
              "      <th>i_e_ratio</th>\n",
              "      <th>rr</th>\n",
              "      <th>tvi</th>\n",
              "      <th>tve</th>\n",
              "      <th>tve_tvi_ratio</th>\n",
              "      <th>max_flow</th>\n",
              "      <th>min_flow</th>\n",
              "      <th>max_pressure</th>\n",
              "      <th>min_pressure</th>\n",
              "      <th>pip</th>\n",
              "      <th>maw</th>\n",
              "      <th>peep</th>\n",
              "      <th>ip_auc</th>\n",
              "      <th>ep_auc</th>\n",
              "      <th>patient</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.66</td>\n",
              "      <td>0.481928</td>\n",
              "      <td>24.390244</td>\n",
              "      <td>481.917778</td>\n",
              "      <td>545.032222</td>\n",
              "      <td>1.130965</td>\n",
              "      <td>51.06</td>\n",
              "      <td>-41.03</td>\n",
              "      <td>17.37</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.37</td>\n",
              "      <td>14.208500</td>\n",
              "      <td>7.600</td>\n",
              "      <td>11.122367</td>\n",
              "      <td>16.057733</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>484.920278</td>\n",
              "      <td>531.880278</td>\n",
              "      <td>1.096841</td>\n",
              "      <td>53.13</td>\n",
              "      <td>-39.97</td>\n",
              "      <td>17.13</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.13</td>\n",
              "      <td>14.149500</td>\n",
              "      <td>7.508</td>\n",
              "      <td>11.077750</td>\n",
              "      <td>17.310533</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.74</td>\n",
              "      <td>0.494253</td>\n",
              "      <td>23.076923</td>\n",
              "      <td>521.370000</td>\n",
              "      <td>523.876667</td>\n",
              "      <td>1.004808</td>\n",
              "      <td>52.86</td>\n",
              "      <td>-38.24</td>\n",
              "      <td>17.11</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.11</td>\n",
              "      <td>14.311860</td>\n",
              "      <td>7.658</td>\n",
              "      <td>12.066000</td>\n",
              "      <td>16.697800</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.64</td>\n",
              "      <td>0.487805</td>\n",
              "      <td>24.590164</td>\n",
              "      <td>482.908333</td>\n",
              "      <td>507.636111</td>\n",
              "      <td>1.051206</td>\n",
              "      <td>51.04</td>\n",
              "      <td>-39.37</td>\n",
              "      <td>17.14</td>\n",
              "      <td>7.04</td>\n",
              "      <td>17.14</td>\n",
              "      <td>14.174500</td>\n",
              "      <td>7.572</td>\n",
              "      <td>11.097800</td>\n",
              "      <td>15.774250</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.94</td>\n",
              "      <td>0.412371</td>\n",
              "      <td>21.897810</td>\n",
              "      <td>466.349722</td>\n",
              "      <td>518.618889</td>\n",
              "      <td>1.112081</td>\n",
              "      <td>47.88</td>\n",
              "      <td>-38.51</td>\n",
              "      <td>16.92</td>\n",
              "      <td>7.04</td>\n",
              "      <td>16.92</td>\n",
              "      <td>14.131250</td>\n",
              "      <td>7.598</td>\n",
              "      <td>11.065400</td>\n",
              "      <td>18.483333</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5967</th>\n",
              "      <td>296</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>349.682222</td>\n",
              "      <td>355.365278</td>\n",
              "      <td>1.016252</td>\n",
              "      <td>42.26</td>\n",
              "      <td>-51.51</td>\n",
              "      <td>23.53</td>\n",
              "      <td>13.00</td>\n",
              "      <td>23.53</td>\n",
              "      <td>21.750667</td>\n",
              "      <td>13.194</td>\n",
              "      <td>19.216400</td>\n",
              "      <td>21.816367</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5968</th>\n",
              "      <td>297</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>350.130000</td>\n",
              "      <td>316.806944</td>\n",
              "      <td>0.904827</td>\n",
              "      <td>42.10</td>\n",
              "      <td>-55.17</td>\n",
              "      <td>24.61</td>\n",
              "      <td>12.80</td>\n",
              "      <td>24.61</td>\n",
              "      <td>22.414667</td>\n",
              "      <td>12.896</td>\n",
              "      <td>19.800467</td>\n",
              "      <td>21.739700</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5969</th>\n",
              "      <td>298</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1.58</td>\n",
              "      <td>0.582278</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>355.670278</td>\n",
              "      <td>395.971111</td>\n",
              "      <td>1.113310</td>\n",
              "      <td>42.95</td>\n",
              "      <td>-22.47</td>\n",
              "      <td>21.35</td>\n",
              "      <td>12.90</td>\n",
              "      <td>21.35</td>\n",
              "      <td>18.785435</td>\n",
              "      <td>13.090</td>\n",
              "      <td>16.997767</td>\n",
              "      <td>21.457600</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5970</th>\n",
              "      <td>299</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>337.941111</td>\n",
              "      <td>373.426389</td>\n",
              "      <td>1.105004</td>\n",
              "      <td>40.34</td>\n",
              "      <td>-36.81</td>\n",
              "      <td>21.69</td>\n",
              "      <td>13.02</td>\n",
              "      <td>21.69</td>\n",
              "      <td>20.308444</td>\n",
              "      <td>13.334</td>\n",
              "      <td>17.944000</td>\n",
              "      <td>21.798167</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5971</th>\n",
              "      <td>300</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>342.556667</td>\n",
              "      <td>364.684444</td>\n",
              "      <td>1.064596</td>\n",
              "      <td>42.29</td>\n",
              "      <td>-45.94</td>\n",
              "      <td>22.69</td>\n",
              "      <td>12.90</td>\n",
              "      <td>22.69</td>\n",
              "      <td>21.145778</td>\n",
              "      <td>13.002</td>\n",
              "      <td>18.679800</td>\n",
              "      <td>21.801950</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5972 rows Ã— 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      breath_id  i_time  e_time  i_e_ratio         rr         tvi         tve  \\\n",
              "0             1    0.80    1.66   0.481928  24.390244  481.917778  545.032222   \n",
              "1             2    0.80    1.80   0.444444  23.076923  484.920278  531.880278   \n",
              "2             3    0.86    1.74   0.494253  23.076923  521.370000  523.876667   \n",
              "3             4    0.80    1.64   0.487805  24.590164  482.908333  507.636111   \n",
              "4             5    0.80    1.94   0.412371  21.897810  466.349722  518.618889   \n",
              "...         ...     ...     ...        ...        ...         ...         ...   \n",
              "5967        296    0.90    1.60   0.562500  24.000000  349.682222  355.365278   \n",
              "5968        297    0.90    1.60   0.562500  24.000000  350.130000  316.806944   \n",
              "5969        298    0.92    1.58   0.582278  24.000000  355.670278  395.971111   \n",
              "5970        299    0.90    1.60   0.562500  24.000000  337.941111  373.426389   \n",
              "5971        300    0.90    1.60   0.562500  24.000000  342.556667  364.684444   \n",
              "\n",
              "      tve_tvi_ratio  max_flow  min_flow  max_pressure  min_pressure    pip  \\\n",
              "0          1.130965     51.06    -41.03         17.37          7.04  17.37   \n",
              "1          1.096841     53.13    -39.97         17.13          7.04  17.13   \n",
              "2          1.004808     52.86    -38.24         17.11          7.04  17.11   \n",
              "3          1.051206     51.04    -39.37         17.14          7.04  17.14   \n",
              "4          1.112081     47.88    -38.51         16.92          7.04  16.92   \n",
              "...             ...       ...       ...           ...           ...    ...   \n",
              "5967       1.016252     42.26    -51.51         23.53         13.00  23.53   \n",
              "5968       0.904827     42.10    -55.17         24.61         12.80  24.61   \n",
              "5969       1.113310     42.95    -22.47         21.35         12.90  21.35   \n",
              "5970       1.105004     40.34    -36.81         21.69         13.02  21.69   \n",
              "5971       1.064596     42.29    -45.94         22.69         12.90  22.69   \n",
              "\n",
              "            maw    peep     ip_auc     ep_auc  patient  \n",
              "0     14.208500   7.600  11.122367  16.057733       66  \n",
              "1     14.149500   7.508  11.077750  17.310533       66  \n",
              "2     14.311860   7.658  12.066000  16.697800       66  \n",
              "3     14.174500   7.572  11.097800  15.774250       66  \n",
              "4     14.131250   7.598  11.065400  18.483333       66  \n",
              "...         ...     ...        ...        ...      ...  \n",
              "5967  21.750667  13.194  19.216400  21.816367      662  \n",
              "5968  22.414667  12.896  19.800467  21.739700      662  \n",
              "5969  18.785435  13.090  16.997767  21.457600      662  \n",
              "5970  20.308444  13.334  17.944000  21.798167      662  \n",
              "5971  21.145778  13.002  18.679800  21.801950      662  \n",
              "\n",
              "[5972 rows x 18 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV5sP7CLKzun"
      },
      "source": [
        "__From Lab2, we know there are only 3 classes in our labels as shown below.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nVdi-lDPKzun",
        "outputId": "a92ad0ff-deb2-47a6-fb7b-5e176bdc7e3d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breath_id</th>\n",
              "      <th>patient</th>\n",
              "      <th>bsa</th>\n",
              "      <th>dta</th>\n",
              "      <th>cough</th>\n",
              "      <th>suction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>292</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>292</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1242</th>\n",
              "      <td>295</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1243</th>\n",
              "      <td>296</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1244</th>\n",
              "      <td>297</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1245</th>\n",
              "      <td>298</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1246</th>\n",
              "      <td>299</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1247 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      breath_id  patient  bsa  dta  cough  suction\n",
              "0            20      292    1    0      0        0\n",
              "1            21      292    1    0      0        0\n",
              "2            22      292    0    0      0        0\n",
              "3            23      292    1    0      0        0\n",
              "4            24      292    1    0      0        0\n",
              "...         ...      ...  ...  ...    ...      ...\n",
              "1242        295      114    0    0      0        0\n",
              "1243        296      114    0    0      0        0\n",
              "1244        297      114    0    0      0        0\n",
              "1245        298      114    0    0      0        0\n",
              "1246        299      114    0    0      0        0\n",
              "\n",
              "[1247 rows x 6 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNrSsxopKzuu"
      },
      "source": [
        "__What does this mean?__\n",
        "\n",
        "We have 6 columns here\n",
        " * *breath_id* - matches with a specific breath identifier from the raw data file.\n",
        " * *patient* - the patient the data came from\n",
        " * *bsa* - Breath Stacking Asynchrony. A single breath where the patient is trapping air in their chest\n",
        " * *dta* - Double Trigger Asynchrony. Two breaths in a row where the patient is trapping air\n",
        " * *cough* - What it sounds like, when a patient coughs\n",
        " * *suction* -  Nurses perform suction procedures to remove excess fluid from an endotracheal tube. This waveform is indicative of that.\n",
        "\n",
        "Now that we understand what our columns are, we need to put it into a format where the machine can understand it and create a learning model. Because this is a multiclass model, let's just have __non-PVA breaths be class 0, breath stacking can be class 1, double trigger can be class 2__.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdoQLqpLKxxT"
      },
      "source": [
        "## Pre-Lab\n",
        "It's often helpful to have data scaled into a certain range of values. For neural networks it is essential, and for random forests it very frequently helps improve performance. There are multiple different ways you can scale your data.\n",
        "\n",
        "#### Standardization\n",
        "A popular method is standardization where you subtract the mean of feature and then divide by its standard deviation.\n",
        "\n",
        "$(x_f - \\mu_f) \\div \\sigma_f$\n",
        "\n",
        "Where $x_f$ is the feature vector, or more simply, a single column in the pandas dataframe.\n",
        "$\\mu_f$ is the mean of the feature vector. Which can also be computed in pandas via `data_frame.column_name.mean()`\n",
        "$\\sigma_f$ is the standard deviation of the feature vector. Which can be computed `data_frame.column_name.std()`.\n",
        "\n",
        "Scikit-Learn has a class to do this that also saves your coefficients.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# initialize scaler with default parameters. To play around with class options check out the scikit-learn\n",
        "# documentation at https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "scaler = StandardScaler()\n",
        "# Fit the scaler to training data, and then scale the training data.\n",
        "train_set_scaled = scaler.fit_transform(train_set)\n",
        "# Transform testing data based on fitted model.\n",
        "#\n",
        "# note the difference here! We don't fit our scaler to the test set because this could bias our model.\n",
        "test_set_scaled = scaler.transform(test_set)\n",
        "```\n",
        "\n",
        "#### Min-Max\n",
        "Min max scaling natively scales all feature vectors between 0 and 1. The math doing this is again pretty simple.\n",
        "\n",
        "$(x_f - min(x_f)) \\div (max(x_f) - min(x_f))$\n",
        "\n",
        "Where the `min` function is just finding the minimum value of a feature vector, and the `max` function is finding the maximum value of a feature vector. You can do this quickly in Scikit-Learn too.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_set_scaled = scaler.fit_transform(train_set)\n",
        "test_set_scaled = scaler.transform(test_set)\n",
        "```\n",
        "\n",
        "#### Robust Scaler\n",
        "Probably the most advanced out of these scalers (but not necessarily better), the robust scaler removes the median of the feature vector, and then scales it according to a quantile range (by default the IQR). This scaler is strong if your data has large amounts of outliers. Different models may also be good with different scalers. Sometimes it is helpful just to play around with your model and see what works.\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "scaler = RobustScaler()\n",
        "train_set_scaled = scaler.fit_transform(train_set)\n",
        "test_set_scaled = scaler.transform(test_set)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9VdtkuF_Knn"
      },
      "source": [
        "### Implement these three scaling methods separately on your Random Forest, SVM, Logistic Regression from Lab 2, compare and discuss the results. Additionally, implement  Random Forest, SVM, Logistic Regression without any scaling. Compare and discuss results. What did you obsever for Logistic Regression? Why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns_to_use = list(set(train_x.columns).difference(['patient', 'breath_id']))\n",
        "t_x = train_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "V5SJXb66Kxxl"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# Fit the scaler to training data, and then scale the training data.\n",
        "scaler.fit(t_x[columns_to_use])\n",
        "train_x_ss = scaler.transform(t_x[columns_to_use])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF & Standardization\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       842\n",
            "           1       0.85      0.97      0.90       301\n",
            "           2       1.00      0.06      0.11       104\n",
            "\n",
            "    accuracy                           0.89      1247\n",
            "   macro avg       0.92      0.66      0.65      1247\n",
            "weighted avg       0.90      0.89      0.86      1247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "RF_model = RandomForestClassifier()\n",
        "RF_model.fit(train_x_ss, train_y_vector)\n",
        "\n",
        "predictions = RF_model.predict(scaler.transform(test_x[columns_to_use]))\n",
        "\n",
        "# Adjust predictions (if needed)\n",
        "for idx, pred in enumerate(predictions):\n",
        "    if pred == 2:\n",
        "        predictions[idx - 1] = 2\n",
        "\n",
        "print(\"RF & Standardization\")\n",
        "RF_report = classification_report(test_y_vector, predictions)\n",
        "print(RF_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR & Standardization\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.85       842\n",
            "           1       0.63      0.73      0.68       301\n",
            "           2       0.33      0.02      0.04       104\n",
            "\n",
            "    accuracy                           0.77      1247\n",
            "   macro avg       0.60      0.54      0.52      1247\n",
            "weighted avg       0.74      0.77      0.74      1247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR_model = LogisticRegression(penalty='l1',solver='saga')\n",
        "LR_model.fit(train_x_ss, train_y_vector)\n",
        "\n",
        "predictions = LR_model.predict(scaler.transform(test_x[columns_to_use]))\n",
        "\n",
        "for idx, pred in enumerate(predictions):\n",
        "    if pred == 2:\n",
        "        predictions[idx - 1] = 2\n",
        "\n",
        "print(\"LR & Standardization\")\n",
        "LR_report = classification_report(test_y_vector, predictions)\n",
        "print(LR_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM & Standardization\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       842\n",
            "           1       0.71      0.80      0.76       301\n",
            "           2       0.44      0.21      0.29       104\n",
            "\n",
            "    accuracy                           0.80      1247\n",
            "   macro avg       0.67      0.63      0.64      1247\n",
            "weighted avg       0.79      0.80      0.79      1247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "SVM_model = SVC()\n",
        "SVM_model.fit(train_x_ss, train_y_vector)\n",
        "predictions = SVM_model.predict(scaler.transform(test_x[columns_to_use]))\n",
        "\n",
        "for idx, pred in enumerate(predictions):\n",
        "    if pred == 2:\n",
        "        predictions[idx-1] = 2\n",
        "\n",
        "print(\"SVM & Standardization\")\n",
        "SVM_report = classification_report(test_y_vector, predictions)        \n",
        "print(SVM_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Min-Max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(t_x[columns_to_use])\n",
        "train_x_mm = scaler.transform(t_x[columns_to_use])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF & Min-Max\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       842\n",
            "           1       0.85      0.96      0.90       301\n",
            "           2       0.75      0.12      0.20       104\n",
            "\n",
            "    accuracy                           0.89      1247\n",
            "   macro avg       0.84      0.68      0.68      1247\n",
            "weighted avg       0.88      0.89      0.86      1247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "RF_model.fit(train_x_mm, train_y_vector)\n",
        "\n",
        "predictions = RF_model.predict(scaler.transform(test_x[columns_to_use]))\n",
        "\n",
        "# Adjust predictions (if needed)\n",
        "for idx, pred in enumerate(predictions):\n",
        "    if pred == 2:\n",
        "        predictions[idx - 1] = 2\n",
        "\n",
        "print(\"RF & Min-Max\")\n",
        "RF_report = classification_report(test_y_vector, predictions)\n",
        "print(RF_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR & Min-Max\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.70      0.78       842\n",
            "           1       0.43      0.81      0.56       301\n",
            "           2       0.50      0.02      0.04       104\n",
            "\n",
            "    accuracy                           0.67      1247\n",
            "   macro avg       0.60      0.51      0.46      1247\n",
            "weighted avg       0.73      0.67      0.66      1247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LR_model.fit(train_x_mm, train_y_vector)\n",
        "\n",
        "predictions = LR_model.predict(scaler.transform(test_x[columns_to_use]))\n",
        "\n",
        "for idx, pred in enumerate(predictions):\n",
        "    if pred == 2:\n",
        "        predictions[idx - 1] = 2\n",
        "\n",
        "print(\"LR & Min-Max\")\n",
        "LR_report = classification_report(test_y_vector, predictions)\n",
        "print(LR_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM & Min-Max\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88       842\n",
            "           1       0.59      0.74      0.66       301\n",
            "           2       1.00      0.04      0.07       104\n",
            "\n",
            "    accuracy                           0.78      1247\n",
            "   macro avg       0.82      0.56      0.54      1247\n",
            "weighted avg       0.81      0.78      0.76      1247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "SVM_model.fit(train_x_mm, train_y_vector)\n",
        "predictions = SVM_model.predict(scaler.transform(test_x[columns_to_use]))\n",
        "\n",
        "for idx, pred in enumerate(predictions):\n",
        "    if pred == 2:\n",
        "        predictions[idx-1] = 2\n",
        "\n",
        "print(\"SVM & Min-Max\")\n",
        "SVM_report = classification_report(test_y_vector, predictions)        \n",
        "print(SVM_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Robust Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "scaler = RobustScaler()\n",
        "scaler.fit(t_x[columns_to_use])\n",
        "train_x_rb = scaler.transform(t_x[columns_to_use])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF & Robust\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       842\n",
            "           1       0.85      0.96      0.90       301\n",
            "           2       0.71      0.10      0.17       104\n",
            "\n",
            "    accuracy                           0.89      1247\n",
            "   macro avg       0.82      0.67      0.67      1247\n",
            "weighted avg       0.87      0.89      0.86      1247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "RF_model.fit(train_x_rb, train_y_vector)\n",
        "\n",
        "predictions = RF_model.predict(scaler.transform(test_x[columns_to_use]))\n",
        "\n",
        "# Adjust predictions (if needed)\n",
        "for idx, pred in enumerate(predictions):\n",
        "    if pred == 2:\n",
        "        predictions[idx - 1] = 2\n",
        "\n",
        "print(\"RF & Robust\")\n",
        "RF_report = classification_report(test_y_vector, predictions)\n",
        "print(RF_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR & Robust\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.94      0.86       842\n",
            "           1       0.64      0.54      0.59       301\n",
            "           2       0.00      0.00      0.00       104\n",
            "\n",
            "    accuracy                           0.77      1247\n",
            "   macro avg       0.48      0.49      0.48      1247\n",
            "weighted avg       0.69      0.77      0.72      1247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LR_model.fit(train_x_rb, train_y_vector)\n",
        "\n",
        "predictions = LR_model.predict(scaler.transform(test_x[columns_to_use]))\n",
        "\n",
        "for idx, pred in enumerate(predictions):\n",
        "    if pred == 2:\n",
        "        predictions[idx - 1] = 2\n",
        "\n",
        "print(\"LR & Robust\")\n",
        "LR_report = classification_report(test_y_vector, predictions)\n",
        "print(LR_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM & Robust\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.98      0.82       842\n",
            "           1       0.48      0.10      0.16       301\n",
            "           2       0.00      0.00      0.00       104\n",
            "\n",
            "    accuracy                           0.69      1247\n",
            "   macro avg       0.39      0.36      0.33      1247\n",
            "weighted avg       0.59      0.69      0.59      1247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "SVM_model.fit(train_x_rb, train_y_vector)\n",
        "predictions = SVM_model.predict(scaler.transform(test_x[columns_to_use]))\n",
        "\n",
        "for idx, pred in enumerate(predictions):\n",
        "    if pred == 2:\n",
        "        predictions[idx-1] = 2\n",
        "\n",
        "print(\"SVM & Robust\")\n",
        "SVM_report = classification_report(test_y_vector, predictions)        \n",
        "print(SVM_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Non-scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF & Non-scaled\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       842\n",
            "           1       0.84      0.96      0.90       301\n",
            "           2       0.50      0.02      0.04       104\n",
            "\n",
            "    accuracy                           0.88      1247\n",
            "   macro avg       0.75      0.65      0.62      1247\n",
            "weighted avg       0.85      0.88      0.85      1247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "RF_model.fit(train_x[columns_to_use], train_y_vector)\n",
        "predictions = RF_model.predict(test_x[columns_to_use])\n",
        "    \n",
        "for idx, pred in enumerate(predictions):\n",
        "    if pred == 2:\n",
        "        predictions[idx-1] = 2\n",
        "\n",
        "print(\"RF & Non-scaled\")\n",
        "RF_report = classification_report(test_y_vector, predictions)\n",
        "print(RF_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR & Non-scaled\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.97      0.85       842\n",
            "           1       0.70      0.38      0.49       301\n",
            "           2       0.00      0.00      0.00       104\n",
            "\n",
            "    accuracy                           0.75      1247\n",
            "   macro avg       0.48      0.45      0.45      1247\n",
            "weighted avg       0.68      0.75      0.69      1247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LR_model.fit(train_x[columns_to_use], train_y_vector)\n",
        "predictions = LR_model.predict(test_x[columns_to_use])\n",
        "    \n",
        "for idx, pred in enumerate(predictions):\n",
        "    if pred == 2:\n",
        "        predictions[idx-1] = 2\n",
        "\n",
        "print(\"LR & Non-scaled\")\n",
        "LR_report = classification_report(test_y_vector, predictions)\n",
        "print(LR_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM & Non-scaled\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.92       842\n",
            "           1       0.76      0.79      0.78       301\n",
            "           2       0.00      0.00      0.00       104\n",
            "\n",
            "    accuracy                           0.85      1247\n",
            "   macro avg       0.55      0.59      0.57      1247\n",
            "weighted avg       0.77      0.85      0.81      1247\n",
            "\n"
          ]
        }
      ],
      "source": [
        "SVM_model.fit(train_x[columns_to_use], train_y_vector)\n",
        "predictions = SVM_model.predict(test_x[columns_to_use])\n",
        "    \n",
        "for idx, pred in enumerate(predictions):\n",
        "    if pred == 2:\n",
        "        predictions[idx-1] = 2\n",
        "\n",
        "print(\"SVM & Non-scaled\")\n",
        "SVM_report = classification_report(test_y_vector, predictions)\n",
        "print(SVM_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Discussion for the results\n",
        "\n",
        "Random Forest (RF):\n",
        "\n",
        "Standardization: In this case, RF achieved an accuracy of 0.89, with reasonably high precision, recall, and F1-scores for class 0 and class 1. However, the F1-score for class 2 is relatively low, indicating difficulty in correctly classifying this class.\n",
        "\n",
        "Min-Max Scaling: Similar to standardization, RF achieved good accuracy (0.89) and high performance for classes 0 and 1, but still struggled with class 2.\n",
        "\n",
        "Robust Scaling: Results are similar to standardization and Min-Max scaling, with good performance for classes 0 and 1 and lower performance for class 2.\n",
        "\n",
        "Non-scaled: RF maintains a high accuracy (0.88) but struggles to classify class 2, as seen in the low F1-score.\n",
        "\n",
        "Logistic Regression (LR):\n",
        "\n",
        "Standardization: LR achieved lower accuracy (0.77) compared to RF. The precision, recall, and F1-scores for class 0 are reasonably good, but LR struggles with class 1 and class 2.\n",
        "\n",
        "Min-Max Scaling: LR performs worse with Min-Max scaling, especially for class 2, where the F1-score is quite low.\n",
        "\n",
        "Robust Scaling: LR's performance remains poor with robust scaling for class 2.\n",
        "\n",
        "Non-scaled: Similar to Min-Max scaling, LR's performance is poor for class 2.\n",
        "\n",
        "Support Vector Machine (SVM):\n",
        "\n",
        "Standardization: SVM performs better than LR but worse than RF, with an accuracy of 0.80. It exhibits good precision and recall for class 0 but struggles with class 1 and class 2.\n",
        "\n",
        "Min-Max Scaling: SVM's performance is relatively consistent with standardization, with some improvement in class 2 recall.\n",
        "\n",
        "Robust Scaling: SVM's performance remains poor for class 2.\n",
        "\n",
        "Non-scaled: SVM performs relatively well, but it still has difficulty classifying class 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### What did you obsever for Logistic Regression? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Standardization:\n",
        "\n",
        "LR tends to perform relatively well with standardization compared with other scaling methods but it is not efficient enough. \n",
        "It achieves a higher accuracy (0.77) compared to Min-Max scaling, Robust scaling, and non-scaling.\n",
        "The precision and recall for class 0 are reasonably good, suggesting that LR can correctly identify this class.\n",
        "However, LR struggles with class 2 with low F1-score, indicating that it has difficulty correctly classifying it.\n",
        "\n",
        "Min-Max Scaling:\n",
        "\n",
        "LR performs worse with Min-Max scaling, achieving the lowest accuracy (0.67) among the scaling methods.\n",
        "The F1-scores for class 2 are notably low, suggesting that LR struggles to correctly classify this class.\n",
        "\n",
        "Robust Scaling:\n",
        "\n",
        "LR's performance with robust scaling is similar to standardization but slightly worse. It achieves an accuracy of 0.77.\n",
        "Like the other scaling methods, it struggles with class 2, showing low F1-scores.\n",
        "\n",
        "Non-scaled:\n",
        "\n",
        "Without any scaling, LR performs better than Min-Max scaling but worse than standardization and robust scaling. It achieves an accuracy of 0.75.\n",
        "Similar to Min-Max scaling, LR struggles to classify class 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the results, LR has a poor performance for classifying class 2, but it is acceptable for class 0 and class 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Conjectures about the causes of LR's performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Logistic Regression (LR) is a linear model commonly used for binary and multiclass classification tasks. With LR, the model learns the relationship between the input features and the target variable by fitting a logistic function (sigmoid) to the linear combination of the features. It then makes predictions by estimating the probability of an instance belonging to a specific class.\n",
        "\n",
        "Like many other machine learning algorithms, LR can be sensitive to the scale of the input features. Feature Scaling ensures that they have similar ranges and helps the algorithm converge faster and reach better results. Standardization (mean centering and scaling to unit variance) and Min-Max scaling (scaling to a specified range, typically [0, 1]) are common scaling techniques used with logistic regression.\n",
        "\n",
        "Due to the sensitivity to Feature Scaling, Robust scaling (using the median and interquartile range) and non-scaling (no scaling at all) can lead to large variations in feature scales, which can negatively impact LR's ability to learn and generalize.\n",
        "\n",
        "Additionally, LR assumes a linear relationship between the features and the log-odds of the target variable. If this assumption does not hold, LR may struggle to model the relationship accurately. In cases where the features have complex nonlinear relationships with the target variable, LR may underperform compared to more flexible models like RF or SVM.\n",
        "\n",
        "Most importantly, if class 2 is imbalanced or has limited data points, LR may struggle to learn a good decision boundary. Imbalanced classes can lead to poor model performance, and LR might not have the capacity to deal with this issue effectively even with scaling.\n",
        "\n",
        "Reference: https://www.sciencedirect.com/topics/computer-science/logistic-regression#:~:text=Logistic%20regression%20is%20a%20process,%2Fno%2C%20and%20so%20on."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
